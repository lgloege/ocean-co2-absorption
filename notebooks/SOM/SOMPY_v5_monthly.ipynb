{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM - CESM Member 001\n",
    "\n",
    "#### Template from 'Basic uses of SOMPY library', modified for our use\n",
    "http://www.vahidmoosavi.com\n",
    "\n",
    "https://github.com/sevamoo/sompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goyetc\\AppData\\Local\\Continuum\\anaconda3\\envs\\sompy_env\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n",
      "backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "# import sompy as sompy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import sompy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "\n",
    "from sompy.sompy import SOMFactory\n",
    "from sompy.visualization.plot_tools import plot_hex_map\n",
    "import logging\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\goyetc\\\\SOMPY'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data for Model\n",
    "* Import data, view basic characteristics\n",
    "* normalize\n",
    "* Observe 2d abstraction of SOM results\n",
    "* Extract cluster designations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'C:\\\\Users\\\\goyetc\\\\ocean-co2-absorption\\\\data'\n",
    "#DATA_DIR = '/Users/cg/co2/'\n",
    "dataset_names = {'pCO2': 'pCO2_2D_mon_CESM001_1x1_198201-201701.nc',\n",
    "                 'XCO2': 'XCO2_1D_mon_CESM001_native_198201-201701.nc',\n",
    "                 'SST': 'SST_2D_mon_CESM001_1x1_198201-201701.nc',\n",
    "                 'SSS': 'SSS_2D_mon_CESM001_1x1_198201-201701.nc',\n",
    "                 'MLD': 'MLD_2D_mon_CESM001_1x1_198201-201701.nc',\n",
    "                 'Chl': 'Chl_2D_mon_CESM001_1x1_198201-201701.nc'}\n",
    "ds = {}\n",
    "for dataset in dataset_names.keys():\n",
    "    filename = os.path.join(DATA_DIR, dataset_names[dataset])\n",
    "    ds[dataset] = xr.open_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "for dataset in ds.keys():\n",
    "    # e.g. pCO2\n",
    "    df[dataset] = ds[dataset][dataset].to_dataframe()\n",
    "    \n",
    "    #note np.isfinite eliminates infinite and/or NaN records from dataset \n",
    "    df[dataset] = df[dataset][np.isfinite(df[dataset][dataset])].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SOM_input = pd.concat([df['SSS'],df['MLD']['MLD'],df['SST']['SST'],df['pCO2']['pCO2']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ylat</th>\n",
       "      <th>xlon</th>\n",
       "      <th>SSS</th>\n",
       "      <th>MLD</th>\n",
       "      <th>SST</th>\n",
       "      <th>pCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982-01-16 12:00:00</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>34.000992</td>\n",
       "      <td>16.192860</td>\n",
       "      <td>1.648732</td>\n",
       "      <td>151.525853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982-01-16 12:00:00</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>180.5</td>\n",
       "      <td>33.941429</td>\n",
       "      <td>15.115437</td>\n",
       "      <td>1.528921</td>\n",
       "      <td>150.330599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982-01-16 12:00:00</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>181.5</td>\n",
       "      <td>33.863464</td>\n",
       "      <td>14.071844</td>\n",
       "      <td>1.350243</td>\n",
       "      <td>148.500409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-01-16 12:00:00</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>182.5</td>\n",
       "      <td>33.775764</td>\n",
       "      <td>13.072312</td>\n",
       "      <td>1.119088</td>\n",
       "      <td>146.198458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982-01-16 12:00:00</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>183.5</td>\n",
       "      <td>33.691376</td>\n",
       "      <td>12.333377</td>\n",
       "      <td>0.865820</td>\n",
       "      <td>143.769723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  ylat   xlon        SSS        MLD       SST        pCO2\n",
       "0 1982-01-16 12:00:00 -77.5  179.5  34.000992  16.192860  1.648732  151.525853\n",
       "1 1982-01-16 12:00:00 -77.5  180.5  33.941429  15.115437  1.528921  150.330599\n",
       "2 1982-01-16 12:00:00 -77.5  181.5  33.863464  14.071844  1.350243  148.500409\n",
       "3 1982-01-16 12:00:00 -77.5  182.5  33.775764  13.072312  1.119088  146.198458\n",
       "4 1982-01-16 12:00:00 -77.5  183.5  33.691376  12.333377  0.865820  143.769723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOM_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out outliers, SSS\n",
    "SOM_input = SOM_input.loc[SOM_input['SSS'] > 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note above: 15k outliers from SSS removed, see scatterplots\n",
    "* Could further constrain data to improve model parameters, but 'lost' data may have more information we don't want to omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOM_input.set_index(pd.DatetimeIndex(SOM_input['time']))\n",
    "SOM_input['month'] = pd.DatetimeIndex(SOM_input['time']).month\n",
    "Monthly = {}\n",
    "for i in range(12):\n",
    "    Monthly['month-'+str(i+1)] = SOM_input.loc[SOM_input['month'] == (i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month-10',\n",
       " 'month-11',\n",
       " 'month-12',\n",
       " 'month-8',\n",
       " 'month-9',\n",
       " 'month-6',\n",
       " 'month-7',\n",
       " 'month-4',\n",
       " 'month-5',\n",
       " 'month-2',\n",
       " 'month-3',\n",
       " 'month-1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Monthly.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    Monthly['month-'+str(i+1)] = Monthly['month-'+str(i+1)].drop(columns='month').sample(frac=1).reset_index(drop=True)\n",
    "    Monthly['month-'+str(i+1)] = Monthly['month-'+str(i+1)].groupby(['ylat','xlon'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   ylat   xlon        SSS        MLD       SST        pCO2\n",
       " 0 -77.5  179.5  33.877541  15.948417  1.349778  155.399963\n",
       " 1 -77.5  180.5  33.831253  15.072249  1.214095  153.832620\n",
       " 2 -77.5  181.5  33.773590  14.233934  1.035777  151.635294\n",
       " 3 -77.5  182.5  33.712555  13.452983  0.825134  149.043507\n",
       " 4 -77.5  183.5  33.657063  12.789043  0.598411  146.350144, (41035, 6))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Monthly['month-1'].head(), Monthly['month-1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choice of normalization or transform? \n",
    "* would like to try sample runs both ways and evaluate performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Prepare data\n",
    "\n",
    "#log(MLD)\n",
    "#means[['MLD']] = means[['MLD']].apply(np.log)\n",
    "\n",
    "#scale\n",
    "ss = StandardScaler().fit_transform(means[['SSS','SST','MLD','pCO2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goyetc\\AppData\\Local\\Continuum\\anaconda3\\envs\\sompy_env\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\goyetc\\AppData\\Local\\Continuum\\anaconda3\\envs\\sompy_env\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#for i in range(12):\n",
    "ss = StandardScaler().fit_transform(Monthly['month-'+str(i+1)][['SSS','SST','MLD','pCO2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012.8548760804778"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning parameters\n",
    "#research suggests M = 5*sqrt(N) is a good choice for number of neurons\n",
    "M = 5*np.sqrt(ss.shape[0])\n",
    "M\n",
    "#insert source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=int(np.sqrt(M))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on SOM tuning\n",
    "* testing suggests pca is faster than random init but limits # of epochs/trainlen internal to SOM engine\n",
    "* batch faster than sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Original SOMtoolbox documentation\n",
    "* http://www.cis.hut.fi/somtoolbox/package/docs2/som_quality.html\n",
    "\n",
    "*     qe : Average distance between each data vector and its BMU.\n",
    "       Measures map resolution.\n",
    "*     te : Topographic error, the proportion of all data vectors\n",
    "       for which first and second BMUs are not adjacent units.\n",
    "       Measures topology preservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 0 has the lowest topographic error so we will use these hyperparameters moving forward\n",
    "* map size = [29,35]\n",
    "* rectangular mapping\n",
    "* pca initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29, 35]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_best.calculate_map_size('rect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_bmu': array([[  5.62000000e+02,   5.62000000e+02,   5.62000000e+02, ...,\n",
       "           2.30000000e+01,   2.30000000e+01,   2.30000000e+01],\n",
       "        [  1.79329921e+00,   1.80683533e+00,   1.81591119e+00, ...,\n",
       "           1.35550033e-02,   1.41659069e-02,   1.47852844e-02]]),\n",
       " '_component_names': [['SSS', 'SST', 'MLD', 'pCO2']],\n",
       " '_data': array([[ 0.18913603, -1.3459917 ,  3.41670057, -2.6790296 ],\n",
       "        [ 0.17588447, -1.3475531 ,  3.41021886, -2.69762985],\n",
       "        [ 0.15916678, -1.34988534,  3.38340523, -2.72281208],\n",
       "        ..., \n",
       "        [-0.84256275, -1.39285668, -0.15187448, -1.19543379],\n",
       "        [-0.84284339, -1.39285576, -0.15225229, -1.19487994],\n",
       "        [-0.84312895, -1.39285485, -0.15263131, -1.19433144]]),\n",
       " '_dim': 4L,\n",
       " '_distance_matrix': array([[  0.00000000e+00,   1.00000000e+00,   4.00000000e+00, ...,\n",
       "           1.19060000e+04,   1.21250000e+04,   1.23460000e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "           1.16890000e+04,   1.19060000e+04,   1.21250000e+04],\n",
       "        [  4.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "           1.14740000e+04,   1.16890000e+04,   1.19060000e+04],\n",
       "        ..., \n",
       "        [  1.19060000e+04,   1.16890000e+04,   1.14740000e+04, ...,\n",
       "           0.00000000e+00,   1.00000000e+00,   4.00000000e+00],\n",
       "        [  1.21250000e+04,   1.19060000e+04,   1.16890000e+04, ...,\n",
       "           1.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "        [  1.23460000e+04,   1.21250000e+04,   1.19060000e+04, ...,\n",
       "           4.00000000e+00,   1.00000000e+00,   0.00000000e+00]]),\n",
       " '_dlabel': None,\n",
       " '_dlen': 41035L,\n",
       " '_normalizer': <sompy.normalization.VarianceNormalizer at 0x7ef5cda0>,\n",
       " 'codebook': <sompy.codebook.Codebook at 0xa39506a0>,\n",
       " 'data_raw': array([[ 0.18913603, -1.3459917 ,  3.41670057, -2.6790296 ],\n",
       "        [ 0.17588447, -1.3475531 ,  3.41021886, -2.69762985],\n",
       "        [ 0.15916678, -1.34988534,  3.38340523, -2.72281208],\n",
       "        ..., \n",
       "        [-0.84256275, -1.39285668, -0.15187448, -1.19543379],\n",
       "        [-0.84284339, -1.39285576, -0.15225229, -1.19487994],\n",
       "        [-0.84312895, -1.39285485, -0.15263131, -1.19433144]]),\n",
       " 'initialization': 'pca',\n",
       " 'mapshape': 'planar',\n",
       " 'mask': array([[ 1.,  1.,  1.,  1.]]),\n",
       " 'name': 'sompy',\n",
       " 'neighborhood': <sompy.neighborhood.GaussianNeighborhood at 0x1c3f66d8>,\n",
       " 'training': 'batch'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_best.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10807846959912271"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_best.calculate_topographic_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10945089303776113"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_best.calculate_quantization_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe effects of various training lengths on best model from above\n",
    "* Note: first pass, same performance was not achieved as the randomly achieved best performance as before. Nevertheless, decent topographical perf and and quant perf achieved\n",
    "* Also note below that various training times do not significantly improve topographical error, and quantization error is basically flat. Implies we can achieve reasonable mapping with low(ish) epochs of rough/fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training...\n",
      " pca_linear_initialization took: 0.054000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 32\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.387000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.390000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.397000, quantization error: 0.654553\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.390000, quantization error: 0.631314\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.391000, quantization error: 0.614198\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.396000, quantization error: 0.601104\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.387000, quantization error: 0.589545\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.387000, quantization error: 0.578247\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.387000, quantization error: 0.567044\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.387000, quantization error: 0.555391\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.388000, quantization error: 0.543574\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.388000, quantization error: 0.531560\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.398000, quantization error: 0.519073\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.389000, quantization error: 0.506170\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.389000, quantization error: 0.492530\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.497000, quantization error: 0.478052\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.502000, quantization error: 0.464039\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.491000, quantization error: 0.451545\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.493000, quantization error: 0.439181\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.491000, quantization error: 0.426489\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.498000, quantization error: 0.413661\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.509000, quantization error: 0.400692\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.502000, quantization error: 0.387420\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.497000, quantization error: 0.374498\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.609000, quantization error: 0.361492\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.493000, quantization error: 0.348333\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.487000, quantization error: 0.335098\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.401000, quantization error: 0.321646\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.388000, quantization error: 0.308232\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.491000, quantization error: 0.294652\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.388000, quantization error: 0.281166\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.386000, quantization error: 0.267624\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 90\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.394000, quantization error: 0.254515\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.501000, quantization error: 0.252222\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.491000, quantization error: 0.250857\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.488000, quantization error: 0.249865\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.492000, quantization error: 0.249169\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.387000, quantization error: 0.248563\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.490000, quantization error: 0.248051\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.389000, quantization error: 0.247546\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.386000, quantization error: 0.247065\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.490000, quantization error: 0.246595\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.495000, quantization error: 0.246148\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.390000, quantization error: 0.245705\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.386000, quantization error: 0.245254\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.387000, quantization error: 0.244814\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.491000, quantization error: 0.244414\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.489000, quantization error: 0.243980\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.388000, quantization error: 0.243478\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.387000, quantization error: 0.242994\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.391000, quantization error: 0.242521\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.242049\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.499000, quantization error: 0.241620\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.496000, quantization error: 0.241248\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.500000, quantization error: 0.240868\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.493000, quantization error: 0.240477\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.392000, quantization error: 0.240072\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.390000, quantization error: 0.239720\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.388000, quantization error: 0.239389\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.239062\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.238747\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.392000, quantization error: 0.238418\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.494000, quantization error: 0.238076\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.390000, quantization error: 0.237715\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.527000, quantization error: 0.237367\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.503000, quantization error: 0.237025\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.502000, quantization error: 0.236647\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.395000, quantization error: 0.236326\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.235946\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.391000, quantization error: 0.235560\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.235208\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.391000, quantization error: 0.234884\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.392000, quantization error: 0.234564\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.390000, quantization error: 0.234234\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.391000, quantization error: 0.233881\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.396000, quantization error: 0.233517\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.395000, quantization error: 0.233194\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.392000, quantization error: 0.232876\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.390000, quantization error: 0.232542\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.391000, quantization error: 0.232203\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.391000, quantization error: 0.231867\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.493000, quantization error: 0.231541\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.496000, quantization error: 0.231235\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.393000, quantization error: 0.230946\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.392000, quantization error: 0.230603\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.392000, quantization error: 0.230289\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.395000, quantization error: 0.229987\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.389000, quantization error: 0.229686\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.396000, quantization error: 0.229399\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.229079\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.390000, quantization error: 0.228762\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.396000, quantization error: 0.228461\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.392000, quantization error: 0.228154\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.391000, quantization error: 0.227850\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.399000, quantization error: 0.227504\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.390000, quantization error: 0.227201\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.391000, quantization error: 0.226903\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.401000, quantization error: 0.226580\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.387000, quantization error: 0.226275\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.393000, quantization error: 0.225978\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.390000, quantization error: 0.225670\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.391000, quantization error: 0.225362\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.389000, quantization error: 0.225068\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.389000, quantization error: 0.224754\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.390000, quantization error: 0.224443\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.394000, quantization error: 0.224155\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.387000, quantization error: 0.223847\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.394000, quantization error: 0.223527\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.389000, quantization error: 0.223198\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.391000, quantization error: 0.222895\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.390000, quantization error: 0.222595\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.388000, quantization error: 0.222309\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.388000, quantization error: 0.222007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 82 ---> elapsed time:  0.389000, quantization error: 0.221726\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.392000, quantization error: 0.221453\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.396000, quantization error: 0.221170\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.402000, quantization error: 0.220880\n",
      "\n",
      " epoch: 86 ---> elapsed time:  0.391000, quantization error: 0.220592\n",
      "\n",
      " epoch: 87 ---> elapsed time:  0.398000, quantization error: 0.220300\n",
      "\n",
      " epoch: 88 ---> elapsed time:  0.391000, quantization error: 0.219984\n",
      "\n",
      " epoch: 89 ---> elapsed time:  0.390000, quantization error: 0.219694\n",
      "\n",
      " epoch: 90 ---> elapsed time:  0.390000, quantization error: 0.219369\n",
      "\n",
      " Final quantization error: 0.219369\n",
      " train took: 51.657000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.060000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 35\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.387000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.393000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.493000, quantization error: 0.655308\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.396000, quantization error: 0.632907\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.616583\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.391000, quantization error: 0.604318\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.403000, quantization error: 0.593707\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.390000, quantization error: 0.583461\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.573258\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.392000, quantization error: 0.562932\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.552256\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.392000, quantization error: 0.541442\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.392000, quantization error: 0.530289\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.518666\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.392000, quantization error: 0.506188\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.391000, quantization error: 0.492884\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.480217\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.392000, quantization error: 0.468931\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.396000, quantization error: 0.457714\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.446374\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.394000, quantization error: 0.434912\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.397000, quantization error: 0.423513\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.395000, quantization error: 0.411995\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.400318\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.395000, quantization error: 0.388590\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.391000, quantization error: 0.376959\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.365083\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.353066\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.340849\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.328549\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.395000, quantization error: 0.315969\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.392000, quantization error: 0.303489\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.290646\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.278018\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.265559\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 83\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.394000, quantization error: 0.253616\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.251488\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.392000, quantization error: 0.250139\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.394000, quantization error: 0.249206\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.248476\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.247904\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.395000, quantization error: 0.247410\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.246905\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.246454\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.246027\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.245625\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.245222\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.395000, quantization error: 0.244733\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.244341\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.498000, quantization error: 0.243951\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.396000, quantization error: 0.243571\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.243126\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.242708\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.398000, quantization error: 0.242244\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.395000, quantization error: 0.241828\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.241369\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.240931\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.399000, quantization error: 0.240464\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.395000, quantization error: 0.240064\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.392000, quantization error: 0.239672\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.239331\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.239007\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.238698\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.238362\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.396000, quantization error: 0.238025\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.395000, quantization error: 0.237686\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.237378\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.237024\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.394000, quantization error: 0.236660\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.236303\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.235952\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.235614\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.394000, quantization error: 0.235263\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.394000, quantization error: 0.234926\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.393000, quantization error: 0.234594\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.394000, quantization error: 0.234242\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.394000, quantization error: 0.233902\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.400000, quantization error: 0.233558\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.233218\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.394000, quantization error: 0.232895\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.395000, quantization error: 0.232551\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.396000, quantization error: 0.232239\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.394000, quantization error: 0.231901\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.395000, quantization error: 0.231556\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.396000, quantization error: 0.231229\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.230915\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.396000, quantization error: 0.230580\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.394000, quantization error: 0.230248\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.395000, quantization error: 0.229911\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.395000, quantization error: 0.229624\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.395000, quantization error: 0.229306\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.396000, quantization error: 0.229000\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.396000, quantization error: 0.228649\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.394000, quantization error: 0.228323\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.397000, quantization error: 0.228016\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.398000, quantization error: 0.227687\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.395000, quantization error: 0.227345\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.394000, quantization error: 0.227010\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.393000, quantization error: 0.226664\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.393000, quantization error: 0.226306\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.394000, quantization error: 0.225946\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.396000, quantization error: 0.225611\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.397000, quantization error: 0.225297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 69 ---> elapsed time:  0.394000, quantization error: 0.224983\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.395000, quantization error: 0.224653\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.395000, quantization error: 0.224329\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.394000, quantization error: 0.224020\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.386000, quantization error: 0.223703\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.396000, quantization error: 0.223383\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.395000, quantization error: 0.223073\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.394000, quantization error: 0.222682\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.395000, quantization error: 0.222333\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.394000, quantization error: 0.222017\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.397000, quantization error: 0.221696\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.403000, quantization error: 0.221374\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.395000, quantization error: 0.221073\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.394000, quantization error: 0.220774\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.392000, quantization error: 0.220477\n",
      "\n",
      " Final quantization error: 0.220477\n",
      " train took: 47.170000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.069000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 38\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.390000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.393000, quantization error: 0.655942\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.397000, quantization error: 0.634265\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.406000, quantization error: 0.618639\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.398000, quantization error: 0.607065\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.597186\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.587823\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.578414\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.569072\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.559481\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.549768\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.539655\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.529184\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.397000, quantization error: 0.517881\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.505366\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.392000, quantization error: 0.493525\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.483256\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.392000, quantization error: 0.472942\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.462509\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.452119\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.497000, quantization error: 0.441684\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.499000, quantization error: 0.431109\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.412000, quantization error: 0.420463\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.398000, quantization error: 0.409871\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.507000, quantization error: 0.399250\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.404000, quantization error: 0.388506\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.399000, quantization error: 0.377876\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.400000, quantization error: 0.367038\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.398000, quantization error: 0.356089\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.344905\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.333553\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.322105\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.394000, quantization error: 0.310801\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.392000, quantization error: 0.299090\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.287294\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.396000, quantization error: 0.275748\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.264375\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 64\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.253393\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.251422\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.392000, quantization error: 0.250085\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.392000, quantization error: 0.249046\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.392000, quantization error: 0.248206\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247471\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.395000, quantization error: 0.246877\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.246340\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.245752\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.245199\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.244677\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.400000, quantization error: 0.244133\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.243602\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.243093\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.242604\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.242072\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.241535\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.241014\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.240427\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.239875\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.386000, quantization error: 0.239382\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.397000, quantization error: 0.238863\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.238379\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.237863\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.237409\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.395000, quantization error: 0.236966\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.236549\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.236145\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.235699\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.235252\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.396000, quantization error: 0.234814\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.234332\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.233866\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.233416\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.232955\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.232508\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.392000, quantization error: 0.232034\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.392000, quantization error: 0.231573\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.394000, quantization error: 0.231115\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.393000, quantization error: 0.230669\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.230223\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.392000, quantization error: 0.229790\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.396000, quantization error: 0.229343\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.394000, quantization error: 0.228901\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.397000, quantization error: 0.228485\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.497000, quantization error: 0.228040\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.396000, quantization error: 0.227608\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.394000, quantization error: 0.227182\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.395000, quantization error: 0.226757\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.392000, quantization error: 0.226335\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.225918\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.392000, quantization error: 0.225500\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.396000, quantization error: 0.225096\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.224650\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.395000, quantization error: 0.224236\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.395000, quantization error: 0.223816\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.395000, quantization error: 0.223384\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.222953\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.396000, quantization error: 0.222523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 60 ---> elapsed time:  0.393000, quantization error: 0.222064\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.394000, quantization error: 0.221645\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.394000, quantization error: 0.221228\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.220825\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.394000, quantization error: 0.220415\n",
      "\n",
      " Final quantization error: 0.220415\n",
      " train took: 41.051000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.071000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 30\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.395000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.496000, quantization error: 0.653962\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.399000, quantization error: 0.630058\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.612299\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.395000, quantization error: 0.598563\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.586218\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.574140\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.562046\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.395000, quantization error: 0.549360\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.392000, quantization error: 0.536590\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.523504\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.510129\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.495979\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.481342\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.466030\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.451216\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.396000, quantization error: 0.437739\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.424095\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.410381\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.396381\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.395000, quantization error: 0.382390\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.368620\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.395000, quantization error: 0.354842\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.397000, quantization error: 0.340766\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.326508\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.392000, quantization error: 0.312226\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.297874\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.283525\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.395000, quantization error: 0.269040\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 75\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.254990\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.392000, quantization error: 0.252589\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.251145\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.397000, quantization error: 0.250134\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.249231\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.248519\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.392000, quantization error: 0.247891\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.392000, quantization error: 0.247280\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.246726\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.246177\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.245711\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.392000, quantization error: 0.245186\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.391000, quantization error: 0.244679\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.244222\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.396000, quantization error: 0.243710\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.243209\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.242671\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.395000, quantization error: 0.242125\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.241583\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.241031\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.240535\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.240067\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.239634\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.239152\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.238693\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.238239\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.237823\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.395000, quantization error: 0.237419\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.392000, quantization error: 0.237021\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.236642\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.392000, quantization error: 0.236241\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.395000, quantization error: 0.235838\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.235460\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.395000, quantization error: 0.235064\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.396000, quantization error: 0.234678\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.396000, quantization error: 0.234297\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.397000, quantization error: 0.233890\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.233505\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.396000, quantization error: 0.233071\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.232592\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.394000, quantization error: 0.232129\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.393000, quantization error: 0.231713\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.231318\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.391000, quantization error: 0.230933\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.230540\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.393000, quantization error: 0.230177\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.393000, quantization error: 0.229796\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.394000, quantization error: 0.229380\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.394000, quantization error: 0.228941\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.394000, quantization error: 0.228581\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.394000, quantization error: 0.228181\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.396000, quantization error: 0.227785\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.394000, quantization error: 0.227367\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.226944\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.393000, quantization error: 0.226559\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.393000, quantization error: 0.226138\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.394000, quantization error: 0.225732\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.225353\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.394000, quantization error: 0.224978\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.395000, quantization error: 0.224573\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.398000, quantization error: 0.224176\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.396000, quantization error: 0.223788\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.396000, quantization error: 0.223406\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.395000, quantization error: 0.223009\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.393000, quantization error: 0.222642\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.393000, quantization error: 0.222031\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.394000, quantization error: 0.221552\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.393000, quantization error: 0.221177\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.393000, quantization error: 0.220797\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.393000, quantization error: 0.220379\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.499000, quantization error: 0.219976\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.397000, quantization error: 0.219616\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.392000, quantization error: 0.219219\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.393000, quantization error: 0.218857\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.399000, quantization error: 0.218490\n",
      "\n",
      " Final quantization error: 0.218490\n",
      " train took: 41.998000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.072000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 36\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.390000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.400000, quantization error: 0.655532\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.506000, quantization error: 0.633385\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.407000, quantization error: 0.617296\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.398000, quantization error: 0.605288\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.594954\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.585000\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.575062\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.565104\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.554767\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.544426\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.533683\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.522402\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.397000, quantization error: 0.510349\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.497334\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.484989\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.474028\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.463127\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.392000, quantization error: 0.452218\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.401000, quantization error: 0.441069\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.429948\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.418725\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.399000, quantization error: 0.407473\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.396164\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.384802\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.492000, quantization error: 0.373412\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.497000, quantization error: 0.361842\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.396000, quantization error: 0.350160\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.338281\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.326242\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.314128\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.301969\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.289552\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.277269\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.265149\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 61\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.253556\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.251465\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.393000, quantization error: 0.250044\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.393000, quantization error: 0.248991\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.392000, quantization error: 0.248153\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247451\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.246760\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.392000, quantization error: 0.246181\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.245616\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.245026\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.244513\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.243946\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.243404\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.242865\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.242322\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.241797\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.241283\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.240695\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.240161\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.392000, quantization error: 0.239619\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.239113\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.238629\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.238095\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.237583\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.237086\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.236646\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.236200\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.235735\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.235261\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.234770\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.388000, quantization error: 0.234287\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.498000, quantization error: 0.233780\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.396000, quantization error: 0.233310\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.396000, quantization error: 0.232813\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.232318\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.231816\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.394000, quantization error: 0.231321\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.394000, quantization error: 0.230841\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.230358\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.400000, quantization error: 0.229920\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.229430\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.395000, quantization error: 0.228981\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.228534\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.228105\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.395000, quantization error: 0.227657\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.393000, quantization error: 0.227230\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.393000, quantization error: 0.226796\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.392000, quantization error: 0.226363\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.393000, quantization error: 0.225920\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.393000, quantization error: 0.225502\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.225062\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.393000, quantization error: 0.224614\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.395000, quantization error: 0.224187\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.403000, quantization error: 0.223750\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.393000, quantization error: 0.223306\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.394000, quantization error: 0.222836\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.393000, quantization error: 0.222395\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.396000, quantization error: 0.221957\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.395000, quantization error: 0.221536\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.392000, quantization error: 0.221099\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.392000, quantization error: 0.220662\n",
      "\n",
      " Final quantization error: 0.220662\n",
      " train took: 39.032000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.066000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 33\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.392000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.498000, quantization error: 0.654820\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.398000, quantization error: 0.631870\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.615039\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.602259\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.396000, quantization error: 0.591004\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.397000, quantization error: 0.580081\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.569208\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.558059\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.397000, quantization error: 0.546622\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.396000, quantization error: 0.535077\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.523051\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.510671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.497443\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.492000, quantization error: 0.483338\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.469777\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.457810\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.415000, quantization error: 0.445791\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.400000, quantization error: 0.433663\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.502000, quantization error: 0.421378\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.408959\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.402000, quantization error: 0.396386\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.383763\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.371039\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.358279\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.345440\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.332546\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.392000, quantization error: 0.319467\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.306475\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.394000, quantization error: 0.293226\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.395000, quantization error: 0.280051\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.399000, quantization error: 0.266902\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 88\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.254236\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.393000, quantization error: 0.251928\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.402000, quantization error: 0.250417\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.394000, quantization error: 0.249467\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.398000, quantization error: 0.248712\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.401000, quantization error: 0.248025\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.247460\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.400000, quantization error: 0.246952\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.246478\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.398000, quantization error: 0.246057\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.245627\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.245190\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.244737\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.244304\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.243919\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.243460\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.243020\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.242613\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.242217\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.392000, quantization error: 0.241855\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.241486\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.395000, quantization error: 0.241125\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.392000, quantization error: 0.240705\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.240295\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.392000, quantization error: 0.239843\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.239476\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.239116\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.392000, quantization error: 0.238782\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.400000, quantization error: 0.238489\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.238187\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.392000, quantization error: 0.237885\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.237611\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.237299\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.237000\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.236681\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.392000, quantization error: 0.236391\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.236065\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.235752\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.392000, quantization error: 0.235421\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.235106\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.392000, quantization error: 0.234774\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.393000, quantization error: 0.234460\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.392000, quantization error: 0.234156\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.392000, quantization error: 0.233803\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.392000, quantization error: 0.233481\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.392000, quantization error: 0.233152\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.392000, quantization error: 0.232789\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.391000, quantization error: 0.232481\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.497000, quantization error: 0.232164\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.396000, quantization error: 0.231845\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.231508\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.394000, quantization error: 0.231204\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.392000, quantization error: 0.230880\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.230535\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.394000, quantization error: 0.230190\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.395000, quantization error: 0.229874\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.393000, quantization error: 0.229562\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.229234\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.397000, quantization error: 0.228919\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.395000, quantization error: 0.228611\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.392000, quantization error: 0.228281\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.395000, quantization error: 0.227946\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.227626\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.393000, quantization error: 0.227320\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.394000, quantization error: 0.227017\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.392000, quantization error: 0.226689\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.398000, quantization error: 0.226381\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.392000, quantization error: 0.226062\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.398000, quantization error: 0.225756\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.407000, quantization error: 0.225458\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.397000, quantization error: 0.225164\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.393000, quantization error: 0.224862\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.392000, quantization error: 0.224554\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.391000, quantization error: 0.224249\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.394000, quantization error: 0.223949\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.393000, quantization error: 0.223655\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.393000, quantization error: 0.223352\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.393000, quantization error: 0.223029\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.396000, quantization error: 0.222720\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.393000, quantization error: 0.222419\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.393000, quantization error: 0.222089\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.392000, quantization error: 0.221784\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.393000, quantization error: 0.221477\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.392000, quantization error: 0.221173\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.392000, quantization error: 0.220879\n",
      "\n",
      " epoch: 86 ---> elapsed time:  0.393000, quantization error: 0.220580\n",
      "\n",
      " epoch: 87 ---> elapsed time:  0.393000, quantization error: 0.220260\n",
      "\n",
      " epoch: 88 ---> elapsed time:  0.397000, quantization error: 0.219921\n",
      "\n",
      " Final quantization error: 0.219921\n",
      " train took: 48.586000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.065000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 33\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.405000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.397000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.400000, quantization error: 0.654820\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.405000, quantization error: 0.631870\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.400000, quantization error: 0.615039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 6 ---> elapsed time:  0.395000, quantization error: 0.602259\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.395000, quantization error: 0.591004\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.580081\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.569208\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.397000, quantization error: 0.558059\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.402000, quantization error: 0.546622\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.535077\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.400000, quantization error: 0.523051\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.391000, quantization error: 0.510671\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.399000, quantization error: 0.497443\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.395000, quantization error: 0.483338\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.399000, quantization error: 0.469777\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.401000, quantization error: 0.457810\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.396000, quantization error: 0.445791\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.433663\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.402000, quantization error: 0.421378\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.392000, quantization error: 0.408959\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.396386\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.392000, quantization error: 0.383763\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.398000, quantization error: 0.371039\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.358279\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.345440\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.332546\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.319467\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.306475\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.293226\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.280051\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.266902\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.254236\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.396000, quantization error: 0.251928\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.250390\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.393000, quantization error: 0.249413\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.248627\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247916\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.392000, quantization error: 0.247321\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.246764\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.246246\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.395000, quantization error: 0.245806\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.245349\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.392000, quantization error: 0.244856\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.244388\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.243934\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.390000, quantization error: 0.243491\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.505000, quantization error: 0.243011\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.242553\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.242115\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.392000, quantization error: 0.241705\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.398000, quantization error: 0.241289\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.240888\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.240471\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.240021\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.239569\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.239148\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.238710\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.238353\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.237972\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.237606\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.392000, quantization error: 0.237251\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.236939\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.394000, quantization error: 0.236605\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.236257\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.235909\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.235567\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.235201\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.394000, quantization error: 0.234840\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.394000, quantization error: 0.234479\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.234101\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.233754\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.233390\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.392000, quantization error: 0.233005\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.395000, quantization error: 0.232682\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.395000, quantization error: 0.232332\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.394000, quantization error: 0.231983\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.393000, quantization error: 0.231626\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.393000, quantization error: 0.231278\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.394000, quantization error: 0.230944\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.397000, quantization error: 0.230592\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.394000, quantization error: 0.230249\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.229908\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.394000, quantization error: 0.229568\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.394000, quantization error: 0.229214\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.400000, quantization error: 0.228860\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.394000, quantization error: 0.228511\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.393000, quantization error: 0.228158\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.394000, quantization error: 0.227827\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.227479\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.397000, quantization error: 0.227134\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.399000, quantization error: 0.226786\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.395000, quantization error: 0.226464\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.395000, quantization error: 0.226113\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.225739\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.395000, quantization error: 0.225395\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.396000, quantization error: 0.225060\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.396000, quantization error: 0.224734\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.397000, quantization error: 0.224407\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.394000, quantization error: 0.224084\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.394000, quantization error: 0.223746\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.395000, quantization error: 0.223385\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.395000, quantization error: 0.223045\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.397000, quantization error: 0.222688\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.395000, quantization error: 0.222323\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.397000, quantization error: 0.222004\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.394000, quantization error: 0.221653\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.395000, quantization error: 0.221322\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.394000, quantization error: 0.221017\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.395000, quantization error: 0.220676\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.395000, quantization error: 0.220351\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.496000, quantization error: 0.220012\n",
      "\n",
      " Final quantization error: 0.220012\n",
      " train took: 45.247000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.082000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 33\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.506000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.396000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.501000, quantization error: 0.654820\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.501000, quantization error: 0.631870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 5 ---> elapsed time:  0.401000, quantization error: 0.615039\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.398000, quantization error: 0.602259\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.591004\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.580081\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.569208\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.558059\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.546622\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.397000, quantization error: 0.535077\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.392000, quantization error: 0.523051\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.510671\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.390000, quantization error: 0.497443\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.396000, quantization error: 0.483338\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.392000, quantization error: 0.469777\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.457810\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.403000, quantization error: 0.445791\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.391000, quantization error: 0.433663\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.392000, quantization error: 0.421378\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.408959\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.390000, quantization error: 0.396386\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.383763\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.371039\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.395000, quantization error: 0.358279\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.345440\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.332546\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.319467\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.306475\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.392000, quantization error: 0.293226\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.392000, quantization error: 0.280051\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.266902\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 79\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.394000, quantization error: 0.254236\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.251928\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.393000, quantization error: 0.250386\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.395000, quantization error: 0.249406\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.248616\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247901\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.247300\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.246746\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.397000, quantization error: 0.246222\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.392000, quantization error: 0.245778\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.245320\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.244806\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.244335\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.243889\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.243456\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.242964\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.397000, quantization error: 0.242510\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.242066\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.397000, quantization error: 0.241661\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.241218\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.398000, quantization error: 0.240829\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.400000, quantization error: 0.240401\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.239945\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.400000, quantization error: 0.239494\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.239080\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.238633\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.238249\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.237868\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.237510\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.237184\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.394000, quantization error: 0.236868\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.395000, quantization error: 0.236532\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.388000, quantization error: 0.236186\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.498000, quantization error: 0.235833\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.235493\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.235142\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.390000, quantization error: 0.234798\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.234429\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.234079\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.395000, quantization error: 0.233714\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.394000, quantization error: 0.233338\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.394000, quantization error: 0.232982\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.392000, quantization error: 0.232631\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.232281\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.231913\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.393000, quantization error: 0.231537\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.393000, quantization error: 0.231194\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.494000, quantization error: 0.230849\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.394000, quantization error: 0.230482\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.398000, quantization error: 0.230111\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.410000, quantization error: 0.229776\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.398000, quantization error: 0.229439\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.496000, quantization error: 0.229070\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.393000, quantization error: 0.228723\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.395000, quantization error: 0.228362\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.394000, quantization error: 0.228024\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.392000, quantization error: 0.227659\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.227295\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.399000, quantization error: 0.226931\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.396000, quantization error: 0.226585\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.394000, quantization error: 0.226248\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.396000, quantization error: 0.225902\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.225535\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.393000, quantization error: 0.225182\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.393000, quantization error: 0.224828\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.400000, quantization error: 0.224477\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.404000, quantization error: 0.224156\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.393000, quantization error: 0.223834\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.394000, quantization error: 0.223486\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.393000, quantization error: 0.223157\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.394000, quantization error: 0.222810\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.393000, quantization error: 0.222451\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.394000, quantization error: 0.222122\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.392000, quantization error: 0.221772\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.392000, quantization error: 0.221421\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.393000, quantization error: 0.221056\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.393000, quantization error: 0.220705\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.393000, quantization error: 0.220346\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.393000, quantization error: 0.219958\n",
      "\n",
      " Final quantization error: 0.219958\n",
      " train took: 45.235000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.066000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 20\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.396000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.397000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.405000, quantization error: 0.649149\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.503000, quantization error: 0.619586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.596560\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.576985\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.396000, quantization error: 0.558249\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.539270\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.519083\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.498257\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.477052\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.455629\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.433599\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.396000, quantization error: 0.411449\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.396000, quantization error: 0.389228\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.366803\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.344548\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.392000, quantization error: 0.323022\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.301465\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.279762\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 42\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.385000, quantization error: 0.258064\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.497000, quantization error: 0.254204\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.251870\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.393000, quantization error: 0.250185\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.248906\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247797\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.246773\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.245853\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.401000, quantization error: 0.244932\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.244105\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.243362\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.242590\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.241874\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.241127\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.240416\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.392000, quantization error: 0.239669\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.238890\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.497000, quantization error: 0.238098\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.397000, quantization error: 0.237280\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.398000, quantization error: 0.236500\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.394000, quantization error: 0.235699\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.395000, quantization error: 0.234929\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.234168\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.233432\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.232749\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.232110\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.231399\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.230698\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.405000, quantization error: 0.229983\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.229268\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.392000, quantization error: 0.228540\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.392000, quantization error: 0.227857\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.397000, quantization error: 0.227131\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.226434\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.397000, quantization error: 0.225698\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.224979\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.392000, quantization error: 0.224257\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.223533\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.222826\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.393000, quantization error: 0.222105\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.221201\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.393000, quantization error: 0.220306\n",
      "\n",
      " Final quantization error: 0.220306\n",
      " train took: 25.046000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.065000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 39\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.392000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.392000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.404000, quantization error: 0.656131\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.397000, quantization error: 0.634666\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.619238\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.607877\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.397000, quantization error: 0.598211\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.589075\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.579899\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.570810\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.561523\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.402000, quantization error: 0.552101\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.542269\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.399000, quantization error: 0.532116\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.404000, quantization error: 0.521133\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.392000, quantization error: 0.509028\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.400000, quantization error: 0.497355\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.392000, quantization error: 0.487377\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.399000, quantization error: 0.477422\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.467218\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.457055\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.446892\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.436752\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.426487\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.396000, quantization error: 0.416212\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.397000, quantization error: 0.405814\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.396000, quantization error: 0.395464\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.385006\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.374546\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.363992\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.398000, quantization error: 0.353280\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.342382\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.397000, quantization error: 0.331336\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.397000, quantization error: 0.320267\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.309181\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.297822\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.399000, quantization error: 0.286346\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.394000, quantization error: 0.275114\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.264036\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 78\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.390000, quantization error: 0.253390\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.251470\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.250214\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.401000, quantization error: 0.249280\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.394000, quantization error: 0.248544\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247944\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.247339\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.246811\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.397000, quantization error: 0.246284\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.245823\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.245391\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.244919\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.395000, quantization error: 0.244446\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.398000, quantization error: 0.244040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.243623\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.243189\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.242779\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.392000, quantization error: 0.242352\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.241872\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.392000, quantization error: 0.241394\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.240923\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.240483\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.240065\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.395000, quantization error: 0.239671\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.239330\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.238994\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.238637\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.238299\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.237933\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.237547\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.237139\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.392000, quantization error: 0.236735\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.236340\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.235948\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.235557\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.235155\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.234757\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.392000, quantization error: 0.234372\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.394000, quantization error: 0.234004\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.392000, quantization error: 0.233619\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.394000, quantization error: 0.233234\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.392000, quantization error: 0.232889\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.394000, quantization error: 0.232544\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.232198\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.396000, quantization error: 0.231800\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.393000, quantization error: 0.231444\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.231072\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.394000, quantization error: 0.230711\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.395000, quantization error: 0.230331\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.393000, quantization error: 0.229968\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.394000, quantization error: 0.229619\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.394000, quantization error: 0.229251\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.399000, quantization error: 0.228894\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.398000, quantization error: 0.228555\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.398000, quantization error: 0.228171\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.394000, quantization error: 0.227792\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.396000, quantization error: 0.227396\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.227050\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.393000, quantization error: 0.226713\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.394000, quantization error: 0.226352\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.394000, quantization error: 0.226007\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.395000, quantization error: 0.225631\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.390000, quantization error: 0.225254\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.395000, quantization error: 0.224888\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.395000, quantization error: 0.224515\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.394000, quantization error: 0.224124\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.394000, quantization error: 0.223767\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.392000, quantization error: 0.223392\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.392000, quantization error: 0.223029\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.393000, quantization error: 0.222688\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.394000, quantization error: 0.222349\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.394000, quantization error: 0.222028\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.392000, quantization error: 0.221687\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.394000, quantization error: 0.221288\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.392000, quantization error: 0.220879\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.393000, quantization error: 0.220539\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.393000, quantization error: 0.220179\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.393000, quantization error: 0.219803\n",
      "\n",
      " Final quantization error: 0.219803\n",
      " train took: 46.587000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.069000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 20\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.395000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.396000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.399000, quantization error: 0.649149\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.502000, quantization error: 0.619586\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.398000, quantization error: 0.596560\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.401000, quantization error: 0.576985\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.395000, quantization error: 0.558249\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.539270\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.519083\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.498257\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.499000, quantization error: 0.477052\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.498000, quantization error: 0.455629\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.433599\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.411449\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.389228\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.366803\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.344548\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.323022\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.392000, quantization error: 0.301465\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.279762\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 92\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.258064\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.254204\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.252177\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.395000, quantization error: 0.250832\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.249897\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.249133\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.248463\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.247920\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.247347\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.398000, quantization error: 0.246909\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.395000, quantization error: 0.246528\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.396000, quantization error: 0.246137\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.396000, quantization error: 0.245739\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.245395\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.392000, quantization error: 0.245073\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.395000, quantization error: 0.244654\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.244276\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.395000, quantization error: 0.243861\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.243449\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.399000, quantization error: 0.243046\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.242642\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.242206\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.396000, quantization error: 0.241798\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.241438\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.241105\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.395000, quantization error: 0.240781\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.240447\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.240107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 29 ---> elapsed time:  0.499000, quantization error: 0.239764\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.395000, quantization error: 0.239414\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.397000, quantization error: 0.239090\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.403000, quantization error: 0.238774\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.238463\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.395000, quantization error: 0.238176\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.395000, quantization error: 0.237854\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.399000, quantization error: 0.237492\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.237116\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.236730\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.236336\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.395000, quantization error: 0.235905\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.394000, quantization error: 0.235509\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.395000, quantization error: 0.235146\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.234820\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.395000, quantization error: 0.234475\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.234120\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.395000, quantization error: 0.233781\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.233440\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.393000, quantization error: 0.233058\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.393000, quantization error: 0.232686\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.393000, quantization error: 0.232334\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.394000, quantization error: 0.231966\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.395000, quantization error: 0.231617\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.395000, quantization error: 0.231305\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.395000, quantization error: 0.230962\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.392000, quantization error: 0.230646\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.392000, quantization error: 0.230329\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.395000, quantization error: 0.229952\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.396000, quantization error: 0.229604\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.394000, quantization error: 0.229302\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.393000, quantization error: 0.229008\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.393000, quantization error: 0.228684\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.393000, quantization error: 0.228420\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.228123\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.393000, quantization error: 0.227838\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.392000, quantization error: 0.227551\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.392000, quantization error: 0.227252\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.394000, quantization error: 0.226934\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.403000, quantization error: 0.226614\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.401000, quantization error: 0.226289\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.391000, quantization error: 0.225935\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.498000, quantization error: 0.225593\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.398000, quantization error: 0.225255\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.499000, quantization error: 0.224917\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.396000, quantization error: 0.224593\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.394000, quantization error: 0.224258\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.397000, quantization error: 0.223958\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.396000, quantization error: 0.223644\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.392000, quantization error: 0.223318\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.397000, quantization error: 0.222998\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.399000, quantization error: 0.222449\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.395000, quantization error: 0.222016\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.394000, quantization error: 0.221663\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.390000, quantization error: 0.221321\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.393000, quantization error: 0.220977\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.393000, quantization error: 0.220637\n",
      "\n",
      " epoch: 86 ---> elapsed time:  0.393000, quantization error: 0.220324\n",
      "\n",
      " epoch: 87 ---> elapsed time:  0.392000, quantization error: 0.220026\n",
      "\n",
      " epoch: 88 ---> elapsed time:  0.397000, quantization error: 0.219722\n",
      "\n",
      " epoch: 89 ---> elapsed time:  0.493000, quantization error: 0.219392\n",
      "\n",
      " epoch: 90 ---> elapsed time:  0.412000, quantization error: 0.219109\n",
      "\n",
      " epoch: 91 ---> elapsed time:  0.396000, quantization error: 0.218803\n",
      "\n",
      " epoch: 92 ---> elapsed time:  0.394000, quantization error: 0.218490\n",
      "\n",
      " Final quantization error: 0.218490\n",
      " train took: 45.390000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.065000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 33\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.400000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.398000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.654820\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.523000, quantization error: 0.631870\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.615039\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.400000, quantization error: 0.602259\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.591004\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.580081\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.569208\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.397000, quantization error: 0.558059\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.546622\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.535077\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.523051\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.510671\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.399000, quantization error: 0.497443\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.396000, quantization error: 0.483338\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.398000, quantization error: 0.469777\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.396000, quantization error: 0.457810\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.445791\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.396000, quantization error: 0.433663\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.396000, quantization error: 0.421378\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.397000, quantization error: 0.408959\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.395000, quantization error: 0.396386\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.383763\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.395000, quantization error: 0.371039\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.358279\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.395000, quantization error: 0.345440\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.332546\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.319467\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.395000, quantization error: 0.306475\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.396000, quantization error: 0.293226\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.396000, quantization error: 0.280051\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.396000, quantization error: 0.266902\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 85\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.392000, quantization error: 0.254236\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.251928\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.250407\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.395000, quantization error: 0.249448\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.394000, quantization error: 0.248686\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.247986\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.247410\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.246898\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.246401\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.397000, quantization error: 0.245967\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.245535\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.245094\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.244616\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.400000, quantization error: 0.244183\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.395000, quantization error: 0.243780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 16 ---> elapsed time:  0.396000, quantization error: 0.243316\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.500000, quantization error: 0.242867\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.398000, quantization error: 0.242445\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.242059\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.395000, quantization error: 0.241645\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.241281\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.397000, quantization error: 0.240885\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.240468\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.240020\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.239589\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.395000, quantization error: 0.239186\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.238813\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.238476\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.238173\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.237848\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.237520\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.237218\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.395000, quantization error: 0.236895\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.394000, quantization error: 0.236584\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.395000, quantization error: 0.236263\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.235938\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.394000, quantization error: 0.235616\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.235283\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.234924\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.394000, quantization error: 0.234592\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.234286\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.398000, quantization error: 0.233978\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.233639\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.394000, quantization error: 0.233308\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.395000, quantization error: 0.232968\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.395000, quantization error: 0.232632\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.232318\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.397000, quantization error: 0.232014\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.395000, quantization error: 0.231696\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.396000, quantization error: 0.231373\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.394000, quantization error: 0.231057\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.393000, quantization error: 0.230723\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.403000, quantization error: 0.230400\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.395000, quantization error: 0.230037\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.393000, quantization error: 0.229670\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.393000, quantization error: 0.229329\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.395000, quantization error: 0.228956\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.228615\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.395000, quantization error: 0.228297\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.393000, quantization error: 0.227973\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.394000, quantization error: 0.227654\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.393000, quantization error: 0.227325\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.397000, quantization error: 0.227003\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.404000, quantization error: 0.226680\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.393000, quantization error: 0.226344\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.392000, quantization error: 0.226029\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.393000, quantization error: 0.225716\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.396000, quantization error: 0.225409\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.394000, quantization error: 0.225094\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.393000, quantization error: 0.224768\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.394000, quantization error: 0.224457\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.392000, quantization error: 0.224137\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.394000, quantization error: 0.223813\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.393000, quantization error: 0.223483\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.394000, quantization error: 0.223154\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.393000, quantization error: 0.222827\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.394000, quantization error: 0.222499\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.393000, quantization error: 0.222178\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.393000, quantization error: 0.221851\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.392000, quantization error: 0.221555\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.394000, quantization error: 0.221246\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.393000, quantization error: 0.220936\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.393000, quantization error: 0.220623\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.393000, quantization error: 0.220317\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.394000, quantization error: 0.219977\n",
      "\n",
      " Final quantization error: 0.219977\n",
      " train took: 47.288000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.063000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 39\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.388000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.656131\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.506000, quantization error: 0.634666\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.619238\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.399000, quantization error: 0.607877\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.396000, quantization error: 0.598211\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.589075\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.579899\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.570810\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.392000, quantization error: 0.561523\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.552101\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.542269\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.532116\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.521133\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.509028\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.497355\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.396000, quantization error: 0.487377\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.477422\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.467218\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.392000, quantization error: 0.457055\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.446892\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.436752\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.402000, quantization error: 0.426487\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.416212\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.405814\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.395464\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.395000, quantization error: 0.385006\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.374546\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.396000, quantization error: 0.363992\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.400000, quantization error: 0.353280\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.394000, quantization error: 0.342382\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.331336\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.396000, quantization error: 0.320267\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.397000, quantization error: 0.309181\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.297822\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.395000, quantization error: 0.286346\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.275114\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.394000, quantization error: 0.264036\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 44\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.253390\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.251470\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.249983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 4 ---> elapsed time:  0.394000, quantization error: 0.248791\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.247809\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.246917\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.246062\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.245232\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.244436\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.243734\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.243014\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.242251\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.241495\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.240846\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.240159\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.395000, quantization error: 0.239441\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.238679\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.237978\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.237238\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.236543\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.394000, quantization error: 0.235840\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.235168\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.234512\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.233862\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.233242\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.232621\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.392000, quantization error: 0.231979\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.398000, quantization error: 0.231329\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.392000, quantization error: 0.230680\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.229977\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.229261\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.228568\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.391000, quantization error: 0.227913\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.399000, quantization error: 0.227252\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.396000, quantization error: 0.226608\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.225981\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.225376\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.224715\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.224025\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.393000, quantization error: 0.223353\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.222703\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.393000, quantization error: 0.222071\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.221449\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.220820\n",
      "\n",
      " Final quantization error: 0.220820\n",
      " train took: 33.170000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.084000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 32\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.497000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.396000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.505000, quantization error: 0.654553\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.397000, quantization error: 0.631314\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.398000, quantization error: 0.614198\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.601104\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.589545\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.392000, quantization error: 0.578247\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.567044\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.555391\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.543574\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.531560\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.519073\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.506170\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.492530\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.397000, quantization error: 0.478052\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.396000, quantization error: 0.464039\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.400000, quantization error: 0.451545\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.439181\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.426489\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.413661\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.396000, quantization error: 0.400692\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.397000, quantization error: 0.387420\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.397000, quantization error: 0.374498\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.397000, quantization error: 0.361492\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.397000, quantization error: 0.348333\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.395000, quantization error: 0.335098\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.321646\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.308232\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.294652\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.281166\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.394000, quantization error: 0.267624\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 69\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.254515\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.252222\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.250778\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.399000, quantization error: 0.249701\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.248918\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.248223\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.399000, quantization error: 0.247627\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.247013\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.246419\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.245835\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.395000, quantization error: 0.245291\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.244754\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.396000, quantization error: 0.244216\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.243745\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.396000, quantization error: 0.243246\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.242659\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.395000, quantization error: 0.242086\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.241520\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.240928\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.240358\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.239875\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.239416\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.238934\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.238487\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.238034\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.237574\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.237165\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.236758\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.396000, quantization error: 0.236370\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.397000, quantization error: 0.235956\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.394000, quantization error: 0.235553\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.396000, quantization error: 0.235154\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.396000, quantization error: 0.234726\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.394000, quantization error: 0.234296\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.397000, quantization error: 0.233849\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.394000, quantization error: 0.233420\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.394000, quantization error: 0.233005\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.232569\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.397000, quantization error: 0.232130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 40 ---> elapsed time:  0.398000, quantization error: 0.231691\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.505000, quantization error: 0.231197\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.398000, quantization error: 0.230710\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.397000, quantization error: 0.230201\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.498000, quantization error: 0.229746\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.399000, quantization error: 0.229306\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.499000, quantization error: 0.228830\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.228396\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.396000, quantization error: 0.227967\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.394000, quantization error: 0.227503\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.395000, quantization error: 0.227026\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.226577\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.392000, quantization error: 0.226123\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.394000, quantization error: 0.225710\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.225297\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.393000, quantization error: 0.224850\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.393000, quantization error: 0.224415\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.393000, quantization error: 0.224003\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.223596\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.400000, quantization error: 0.223192\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.393000, quantization error: 0.222797\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.395000, quantization error: 0.222389\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.393000, quantization error: 0.221971\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.397000, quantization error: 0.221299\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.399000, quantization error: 0.220758\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.395000, quantization error: 0.220320\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.399000, quantization error: 0.219883\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.393000, quantization error: 0.219452\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.393000, quantization error: 0.219054\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.392000, quantization error: 0.218679\n",
      "\n",
      " Final quantization error: 0.218679\n",
      " train took: 40.829000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.065000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 20\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.501000, quantization error: 0.649149\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.500000, quantization error: 0.619586\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.400000, quantization error: 0.596560\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.396000, quantization error: 0.576985\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.399000, quantization error: 0.558249\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.539270\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.519083\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.498257\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.477052\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.455629\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.433599\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.411449\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.389228\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.395000, quantization error: 0.366803\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.344548\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.399000, quantization error: 0.323022\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.301465\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.279762\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 49\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.258064\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.399000, quantization error: 0.254204\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.396000, quantization error: 0.251951\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.395000, quantization error: 0.250356\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.249163\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.248143\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.247216\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.246412\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.245562\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.244894\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.244238\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.243571\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.242952\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.242316\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.395000, quantization error: 0.241674\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.241000\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.392000, quantization error: 0.240364\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.392000, quantization error: 0.239634\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.238944\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.395000, quantization error: 0.238204\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.237472\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.236808\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.392000, quantization error: 0.236147\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.235547\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.396000, quantization error: 0.234895\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.397000, quantization error: 0.234315\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.394000, quantization error: 0.233768\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.395000, quantization error: 0.233196\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.232610\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.495000, quantization error: 0.231986\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.495000, quantization error: 0.231351\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.396000, quantization error: 0.230740\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.230133\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.229490\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.228861\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.228253\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.397000, quantization error: 0.227656\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.227091\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.394000, quantization error: 0.226487\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.394000, quantization error: 0.225853\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.225218\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.394000, quantization error: 0.224531\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.397000, quantization error: 0.223863\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.397000, quantization error: 0.223249\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.222655\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.402000, quantization error: 0.221983\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.221148\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.398000, quantization error: 0.220472\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.403000, quantization error: 0.219838\n",
      "\n",
      " Final quantization error: 0.219838\n",
      " train took: 27.944000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.067000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 24\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.392000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.396000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.397000, quantization error: 0.651576\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.506000, quantization error: 0.624881\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.604555\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.398000, quantization error: 0.588012\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.398000, quantization error: 0.572601\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.557110\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.541210\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.396000, quantization error: 0.524668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 11 ---> elapsed time:  0.397000, quantization error: 0.507766\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.490490\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.395000, quantization error: 0.472856\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.454811\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.392000, quantization error: 0.436250\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.417276\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.398507\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.380961\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.363662\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.391000, quantization error: 0.346311\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.328695\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.310796\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.292639\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.274369\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 85\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.405000, quantization error: 0.256381\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.253155\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.397000, quantization error: 0.251381\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.396000, quantization error: 0.250206\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.249267\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.392000, quantization error: 0.248479\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.247746\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.247077\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.392000, quantization error: 0.246526\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.392000, quantization error: 0.246051\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.392000, quantization error: 0.245652\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.245226\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.391000, quantization error: 0.244872\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.394000, quantization error: 0.244457\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.391000, quantization error: 0.244101\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.392000, quantization error: 0.243696\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.392000, quantization error: 0.243290\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.242855\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.390000, quantization error: 0.242418\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.391000, quantization error: 0.241981\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.396000, quantization error: 0.241553\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.241151\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.391000, quantization error: 0.240766\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.240440\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.391000, quantization error: 0.240101\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.239772\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.391000, quantization error: 0.239404\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.392000, quantization error: 0.239028\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.399000, quantization error: 0.238670\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.391000, quantization error: 0.238309\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.237969\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.394000, quantization error: 0.237626\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.237263\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.392000, quantization error: 0.236912\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.392000, quantization error: 0.236531\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.392000, quantization error: 0.236175\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.235835\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.392000, quantization error: 0.235494\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.389000, quantization error: 0.235158\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.394000, quantization error: 0.234849\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.234534\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.393000, quantization error: 0.234220\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.233873\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.392000, quantization error: 0.233519\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.392000, quantization error: 0.233127\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.391000, quantization error: 0.232750\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.395000, quantization error: 0.232389\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.393000, quantization error: 0.232032\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.393000, quantization error: 0.231641\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.393000, quantization error: 0.231285\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.396000, quantization error: 0.230934\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.393000, quantization error: 0.230574\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.398000, quantization error: 0.230154\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.393000, quantization error: 0.229723\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.394000, quantization error: 0.229278\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.394000, quantization error: 0.228831\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.396000, quantization error: 0.228455\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.228107\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.394000, quantization error: 0.227761\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.397000, quantization error: 0.227384\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.392000, quantization error: 0.227046\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.393000, quantization error: 0.226688\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.392000, quantization error: 0.226350\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.396000, quantization error: 0.225962\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.394000, quantization error: 0.225612\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.395000, quantization error: 0.225261\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.394000, quantization error: 0.224925\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.398000, quantization error: 0.224610\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.395000, quantization error: 0.224286\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.394000, quantization error: 0.223944\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.394000, quantization error: 0.223618\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.395000, quantization error: 0.223283\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.394000, quantization error: 0.222909\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.391000, quantization error: 0.222296\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.393000, quantization error: 0.221814\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.394000, quantization error: 0.221439\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.395000, quantization error: 0.221083\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.395000, quantization error: 0.220673\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.394000, quantization error: 0.220319\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.394000, quantization error: 0.220019\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.395000, quantization error: 0.219684\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.394000, quantization error: 0.219372\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.393000, quantization error: 0.219054\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.395000, quantization error: 0.218721\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.394000, quantization error: 0.218388\n",
      "\n",
      " Final quantization error: 0.218388\n",
      " train took: 43.458000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.072000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 23\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.399000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.651052\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.407000, quantization error: 0.623746\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.401000, quantization error: 0.602847\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.399000, quantization error: 0.585644\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.399000, quantization error: 0.569498\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.553220\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.536486\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.397000, quantization error: 0.518998\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.501149\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.483021\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.464511\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.445514\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.426163\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.406552\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.386914\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.395000, quantization error: 0.368196\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.350279\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.332086\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.394000, quantization error: 0.313523\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.294601\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.275562\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 49\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.507000, quantization error: 0.256768\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.497000, quantization error: 0.253339\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.251228\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.395000, quantization error: 0.249717\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.248501\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247529\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.246540\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.394000, quantization error: 0.245735\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.244962\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.244264\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.243625\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.242974\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.242352\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.241733\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.392000, quantization error: 0.241078\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.240448\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.239761\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.239105\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.238456\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.237758\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.237075\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.236390\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.235755\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.235152\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.402000, quantization error: 0.234558\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.233957\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.395000, quantization error: 0.233376\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.232752\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.396000, quantization error: 0.232199\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.231603\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.231009\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.230413\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.229815\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.229207\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.228637\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.393000, quantization error: 0.228022\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.227393\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.226774\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.226145\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.392000, quantization error: 0.225497\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.390000, quantization error: 0.224815\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.392000, quantization error: 0.224195\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.394000, quantization error: 0.223642\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.392000, quantization error: 0.223069\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.222476\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.394000, quantization error: 0.221840\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.392000, quantization error: 0.220985\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.393000, quantization error: 0.220262\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.394000, quantization error: 0.219580\n",
      "\n",
      " Final quantization error: 0.219580\n",
      " train took: 28.929000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.062000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 38\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.390000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.393000, quantization error: 0.655942\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.507000, quantization error: 0.634265\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.398000, quantization error: 0.618639\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.401000, quantization error: 0.607065\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.398000, quantization error: 0.597186\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.398000, quantization error: 0.587823\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.578414\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.569072\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.559481\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.549768\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.392000, quantization error: 0.539655\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.529184\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.517881\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.505366\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.493525\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.395000, quantization error: 0.483256\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.472942\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.462509\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.503000, quantization error: 0.452119\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.396000, quantization error: 0.441684\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.395000, quantization error: 0.431109\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.420463\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.499000, quantization error: 0.409871\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.500000, quantization error: 0.399250\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.400000, quantization error: 0.388506\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.401000, quantization error: 0.377876\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.498000, quantization error: 0.367038\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.397000, quantization error: 0.356089\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.400000, quantization error: 0.344905\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.400000, quantization error: 0.333553\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.322105\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.395000, quantization error: 0.310801\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.299090\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.395000, quantization error: 0.287294\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.396000, quantization error: 0.275748\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.264375\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 51\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.253393\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.393000, quantization error: 0.251422\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.394000, quantization error: 0.249991\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.396000, quantization error: 0.248856\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.247913\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247096\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.246359\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.245694\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.244993\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.244324\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.243679\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.243037\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.398000, quantization error: 0.242410\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.241815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 15 ---> elapsed time:  0.393000, quantization error: 0.241199\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.392000, quantization error: 0.240561\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.239917\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.239282\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.238597\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.393000, quantization error: 0.237944\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.237354\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.395000, quantization error: 0.236772\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.236196\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.235611\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.235063\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.393000, quantization error: 0.234495\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.391000, quantization error: 0.233907\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.233288\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.232715\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.232162\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.231596\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.394000, quantization error: 0.231060\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.393000, quantization error: 0.230501\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.229913\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.229331\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.395000, quantization error: 0.228728\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.228144\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.394000, quantization error: 0.227609\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.393000, quantization error: 0.227076\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.394000, quantization error: 0.226516\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.225981\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.394000, quantization error: 0.225455\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.395000, quantization error: 0.224934\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.395000, quantization error: 0.224369\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.394000, quantization error: 0.223818\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.394000, quantization error: 0.223288\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.391000, quantization error: 0.222766\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.393000, quantization error: 0.222260\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.393000, quantization error: 0.221758\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.393000, quantization error: 0.221243\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.394000, quantization error: 0.220712\n",
      "\n",
      " Final quantization error: 0.220712\n",
      " train took: 35.991000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.066000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 33\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.390000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.402000, quantization error: 0.654820\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.507000, quantization error: 0.631870\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.396000, quantization error: 0.615039\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.399000, quantization error: 0.602259\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.395000, quantization error: 0.591004\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.395000, quantization error: 0.580081\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.569208\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.397000, quantization error: 0.558059\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.395000, quantization error: 0.546622\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.397000, quantization error: 0.535077\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.496000, quantization error: 0.523051\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.503000, quantization error: 0.510671\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.397000, quantization error: 0.497443\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.395000, quantization error: 0.483338\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.469777\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.396000, quantization error: 0.457810\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.445791\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.395000, quantization error: 0.433663\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.394000, quantization error: 0.421378\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.393000, quantization error: 0.408959\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.396386\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.394000, quantization error: 0.383763\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.395000, quantization error: 0.371039\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.358279\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.345440\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.332546\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.319467\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.306475\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.395000, quantization error: 0.293226\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.395000, quantization error: 0.280051\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.395000, quantization error: 0.266902\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 66\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.392000, quantization error: 0.254236\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.251928\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.250328\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.396000, quantization error: 0.249285\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.394000, quantization error: 0.248434\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.247641\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.246982\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.246362\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.395000, quantization error: 0.245776\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.245225\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.394000, quantization error: 0.244704\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.244166\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.243641\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.395000, quantization error: 0.243109\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.396000, quantization error: 0.242593\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.242062\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.395000, quantization error: 0.241533\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.394000, quantization error: 0.241024\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.240503\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.396000, quantization error: 0.240030\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.239571\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.396000, quantization error: 0.239061\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.395000, quantization error: 0.238571\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.395000, quantization error: 0.238035\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.396000, quantization error: 0.237514\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.237009\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.393000, quantization error: 0.236556\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.396000, quantization error: 0.236146\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.235735\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.391000, quantization error: 0.235329\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.396000, quantization error: 0.234909\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.396000, quantization error: 0.234502\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.234068\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.394000, quantization error: 0.233667\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.233250\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.395000, quantization error: 0.232798\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.395000, quantization error: 0.232326\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.398000, quantization error: 0.231890\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.231448\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.231048\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.393000, quantization error: 0.230662\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.394000, quantization error: 0.230261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 43 ---> elapsed time:  0.394000, quantization error: 0.229821\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.393000, quantization error: 0.229392\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.228980\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.394000, quantization error: 0.228561\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.396000, quantization error: 0.228108\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.395000, quantization error: 0.227691\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.392000, quantization error: 0.227273\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.394000, quantization error: 0.226859\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.226446\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.392000, quantization error: 0.226036\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.394000, quantization error: 0.225605\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.225186\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.394000, quantization error: 0.224767\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.392000, quantization error: 0.224359\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.393000, quantization error: 0.223938\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.223509\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.393000, quantization error: 0.223084\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.393000, quantization error: 0.222670\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.398000, quantization error: 0.222232\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.393000, quantization error: 0.221795\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.392000, quantization error: 0.221375\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.395000, quantization error: 0.220966\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.394000, quantization error: 0.220552\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.395000, quantization error: 0.220140\n",
      "\n",
      " Final quantization error: 0.220140\n",
      " train took: 39.765000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.069000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 30\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.396000, quantization error: 0.895949\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.708758\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.509000, quantization error: 0.653962\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.502000, quantization error: 0.630058\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.499000, quantization error: 0.612299\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.598563\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.586218\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.574140\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.562046\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.393000, quantization error: 0.549360\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.536590\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.393000, quantization error: 0.523504\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.394000, quantization error: 0.510129\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.495979\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.481342\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.393000, quantization error: 0.466030\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.394000, quantization error: 0.451216\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.393000, quantization error: 0.437739\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.393000, quantization error: 0.424095\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.394000, quantization error: 0.410381\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.396381\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.394000, quantization error: 0.382390\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.368620\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.392000, quantization error: 0.354842\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.340766\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.394000, quantization error: 0.326508\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.395000, quantization error: 0.312226\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.393000, quantization error: 0.297874\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.393000, quantization error: 0.283525\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.393000, quantization error: 0.269040\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 89\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.393000, quantization error: 0.254990\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.392000, quantization error: 0.252589\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.393000, quantization error: 0.251194\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.392000, quantization error: 0.250234\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.393000, quantization error: 0.249401\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.392000, quantization error: 0.248727\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.394000, quantization error: 0.248168\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.392000, quantization error: 0.247621\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.393000, quantization error: 0.247132\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.392000, quantization error: 0.246656\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.395000, quantization error: 0.246216\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.392000, quantization error: 0.245768\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.393000, quantization error: 0.245280\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.392000, quantization error: 0.244861\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.244421\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.392000, quantization error: 0.243979\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.243487\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.391000, quantization error: 0.243014\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.394000, quantization error: 0.242524\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.392000, quantization error: 0.242027\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.392000, quantization error: 0.241569\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.395000, quantization error: 0.241178\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.393000, quantization error: 0.240776\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.240387\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.394000, quantization error: 0.240012\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.239625\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.395000, quantization error: 0.239260\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.394000, quantization error: 0.238908\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.394000, quantization error: 0.238577\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.394000, quantization error: 0.238242\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.395000, quantization error: 0.237902\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.393000, quantization error: 0.237572\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.392000, quantization error: 0.237242\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.396000, quantization error: 0.236853\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.394000, quantization error: 0.236488\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.494000, quantization error: 0.236134\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.499000, quantization error: 0.235775\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.235435\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.235127\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.395000, quantization error: 0.234795\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.234423\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.397000, quantization error: 0.234058\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.395000, quantization error: 0.233745\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.394000, quantization error: 0.233418\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.393000, quantization error: 0.233101\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.395000, quantization error: 0.232759\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.396000, quantization error: 0.232417\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.395000, quantization error: 0.232112\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.396000, quantization error: 0.231758\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.395000, quantization error: 0.231399\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.231071\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.394000, quantization error: 0.230758\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.396000, quantization error: 0.230432\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.394000, quantization error: 0.230074\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.394000, quantization error: 0.229741\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.395000, quantization error: 0.229408\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.398000, quantization error: 0.229080\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.394000, quantization error: 0.228761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 59 ---> elapsed time:  0.394000, quantization error: 0.228437\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.394000, quantization error: 0.228137\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.394000, quantization error: 0.227840\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.394000, quantization error: 0.227528\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.393000, quantization error: 0.227201\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.394000, quantization error: 0.226849\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.398000, quantization error: 0.226504\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.395000, quantization error: 0.226159\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.393000, quantization error: 0.225843\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.393000, quantization error: 0.225539\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.392000, quantization error: 0.225202\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.394000, quantization error: 0.224884\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.393000, quantization error: 0.224559\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.392000, quantization error: 0.224186\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.394000, quantization error: 0.223835\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.395000, quantization error: 0.223523\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.394000, quantization error: 0.223219\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.395000, quantization error: 0.222903\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.393000, quantization error: 0.222545\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.394000, quantization error: 0.221994\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.394000, quantization error: 0.221608\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.393000, quantization error: 0.221266\n",
      "\n",
      " epoch: 81 ---> elapsed time:  0.393000, quantization error: 0.220927\n",
      "\n",
      " epoch: 82 ---> elapsed time:  0.395000, quantization error: 0.220573\n",
      "\n",
      " epoch: 83 ---> elapsed time:  0.395000, quantization error: 0.220267\n",
      "\n",
      " epoch: 84 ---> elapsed time:  0.394000, quantization error: 0.219976\n",
      "\n",
      " epoch: 85 ---> elapsed time:  0.392000, quantization error: 0.219690\n",
      "\n",
      " epoch: 86 ---> elapsed time:  0.394000, quantization error: 0.219416\n",
      "\n",
      " epoch: 87 ---> elapsed time:  0.395000, quantization error: 0.219124\n",
      "\n",
      " epoch: 88 ---> elapsed time:  0.395000, quantization error: 0.218808\n",
      "\n",
      " epoch: 89 ---> elapsed time:  0.393000, quantization error: 0.218518\n",
      "\n",
      " Final quantization error: 0.218518\n",
      " train took: 47.840000 seconds\n"
     ]
    }
   ],
   "source": [
    "map_best = mean_best.calculate_map_size('rect')\n",
    "names = ['SSS','SST','MLD','pCO2']\n",
    "\n",
    "for i in range(12): \n",
    "    \n",
    "    \n",
    "    sm = sompy.SOMFactory().build(ss, mapsize = map_best, mapshape = 'planar',\n",
    "                            initialization='pca',\n",
    "                            normalization = 'var', \n",
    "                            component_names=names, lattice='rect') \n",
    "    sm.train(n_job=4, \n",
    "             verbose='info', \n",
    "             train_rough_len=random.choice(list(range(20,40))),\n",
    "             train_finetune_len=random.choice(list(range(40,100))),\n",
    "             #train_rough_radiusin=14,\n",
    "             #train_rough_radiusfin=3.5,\n",
    "             #train_finetune_radiusin=3.5,\n",
    "             #train_finetune_radiusfin=1\n",
    "            ) \n",
    "    \n",
    "    joblib.dump(sm, \"model_mean_opt_r3_epochs_{}.joblib\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " find_bmu took: 5.650000 seconds\n",
      " find_bmu took: 0.849000 seconds\n",
      " find_bmu took: 0.733000 seconds\n",
      " find_bmu took: 0.728000 seconds\n",
      " find_bmu took: 0.774000 seconds\n",
      " find_bmu took: 0.744000 seconds\n",
      " find_bmu took: 0.728000 seconds\n",
      " find_bmu took: 0.843000 seconds\n",
      " find_bmu took: 0.737000 seconds\n",
      " find_bmu took: 0.740000 seconds\n",
      " find_bmu took: 0.829000 seconds\n",
      " find_bmu took: 0.651000 seconds\n",
      " find_bmu took: 0.752000 seconds\n",
      " find_bmu took: 0.823000 seconds\n",
      " find_bmu took: 0.659000 seconds\n",
      " find_bmu took: 0.728000 seconds\n",
      " find_bmu took: 0.856000 seconds\n",
      " find_bmu took: 0.731000 seconds\n",
      " find_bmu took: 0.733000 seconds\n",
      " find_bmu took: 0.830000 seconds\n",
      " find_bmu took: 0.739000 seconds\n",
      " find_bmu took: 0.686000 seconds\n",
      " find_bmu took: 0.772000 seconds\n",
      " find_bmu took: 0.655000 seconds\n",
      " find_bmu took: 0.680000 seconds\n",
      " find_bmu took: 0.854000 seconds\n",
      " find_bmu took: 0.748000 seconds\n",
      " find_bmu took: 0.732000 seconds\n",
      " find_bmu took: 0.933000 seconds\n",
      " find_bmu took: 0.835000 seconds\n",
      " find_bmu took: 0.751000 seconds\n",
      " find_bmu took: 0.839000 seconds\n",
      " find_bmu took: 0.749000 seconds\n",
      " find_bmu took: 0.736000 seconds\n",
      " find_bmu took: 0.765000 seconds\n",
      " find_bmu took: 0.730000 seconds\n",
      " find_bmu took: 0.755000 seconds\n",
      " find_bmu took: 0.833000 seconds\n",
      " find_bmu took: 0.751000 seconds\n",
      " find_bmu took: 0.757000 seconds\n",
      " find_bmu took: 0.753000 seconds\n",
      " find_bmu took: 0.664000 seconds\n",
      " find_bmu took: 0.746000 seconds\n",
      " find_bmu took: 0.948000 seconds\n",
      " find_bmu took: 0.764000 seconds\n",
      " find_bmu took: 0.737000 seconds\n",
      " find_bmu took: 0.870000 seconds\n",
      " find_bmu took: 0.646000 seconds\n",
      " find_bmu took: 0.725000 seconds\n",
      " find_bmu took: 0.841000 seconds\n",
      " find_bmu took: 0.773000 seconds\n",
      " find_bmu took: 0.751000 seconds\n",
      " find_bmu took: 0.873000 seconds\n",
      " find_bmu took: 0.667000 seconds\n",
      " find_bmu took: 0.749000 seconds\n",
      " find_bmu took: 0.949000 seconds\n",
      " find_bmu took: 0.671000 seconds\n",
      " find_bmu took: 0.643000 seconds\n",
      " find_bmu took: 0.752000 seconds\n",
      " find_bmu took: 0.761000 seconds\n"
     ]
    }
   ],
   "source": [
    "# Study the models trained and plot the errors obtained in order to select the best one\n",
    "models_pool_r3 = glob.glob(\"./model_mean_opt_r3*\")\n",
    "errors=[]\n",
    "for model_filepath in models_pool_r3:\n",
    "    sm_r3 = joblib.load(model_filepath)\n",
    "    topographic_error = sm_r3.calculate_topographic_error()\n",
    "    quantization_error = sm_r3.calculate_quantization_error()\n",
    "    errors.append((topographic_error, quantization_error))\n",
    "e_top_r3, e_q_r3 = zip(*errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(e_top_r3, e_q_r3)\n",
    "plt.title(\"Best Model From Network Tuning, Various Training Length (n epochs) Effects\")\n",
    "plt.xlabel(\"Topographic error\")\n",
    "plt.ylabel(\"Quantization error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization_error</th>\n",
       "      <th>topographical_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_10.joblib</td>\n",
       "      <td>0.090950</td>\n",
       "      <td>0.152431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_16.joblib</td>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.152991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_19.joblib</td>\n",
       "      <td>0.090944</td>\n",
       "      <td>0.154454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_8.joblib</td>\n",
       "      <td>0.091472</td>\n",
       "      <td>0.154722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_14.joblib</td>\n",
       "      <td>0.091376</td>\n",
       "      <td>0.154843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_3.joblib</td>\n",
       "      <td>0.090950</td>\n",
       "      <td>0.156013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_15.joblib</td>\n",
       "      <td>0.090948</td>\n",
       "      <td>0.156452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_0.joblib</td>\n",
       "      <td>0.091345</td>\n",
       "      <td>0.156720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_9.joblib</td>\n",
       "      <td>0.091465</td>\n",
       "      <td>0.156890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_7.joblib</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>0.157427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_5.joblib</td>\n",
       "      <td>0.091520</td>\n",
       "      <td>0.158036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_11.joblib</td>\n",
       "      <td>0.091532</td>\n",
       "      <td>0.158158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_6.joblib</td>\n",
       "      <td>0.091565</td>\n",
       "      <td>0.158426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_2.joblib</td>\n",
       "      <td>0.091729</td>\n",
       "      <td>0.158645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_17.joblib</td>\n",
       "      <td>0.091789</td>\n",
       "      <td>0.159035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_1.joblib</td>\n",
       "      <td>0.091836</td>\n",
       "      <td>0.159401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_12.joblib</td>\n",
       "      <td>0.091766</td>\n",
       "      <td>0.159937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_4.joblib</td>\n",
       "      <td>0.091819</td>\n",
       "      <td>0.160083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_18.joblib</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>0.160229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.\\model_mean_opt_r3_epochs_13.joblib</td>\n",
       "      <td>0.090951</td>\n",
       "      <td>0.160668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model  quantization_error  \\\n",
       "2   .\\model_mean_opt_r3_epochs_10.joblib            0.090950   \n",
       "8   .\\model_mean_opt_r3_epochs_16.joblib            0.091271   \n",
       "11  .\\model_mean_opt_r3_epochs_19.joblib            0.090944   \n",
       "18   .\\model_mean_opt_r3_epochs_8.joblib            0.091472   \n",
       "6   .\\model_mean_opt_r3_epochs_14.joblib            0.091376   \n",
       "13   .\\model_mean_opt_r3_epochs_3.joblib            0.090950   \n",
       "7   .\\model_mean_opt_r3_epochs_15.joblib            0.090948   \n",
       "0    .\\model_mean_opt_r3_epochs_0.joblib            0.091345   \n",
       "19   .\\model_mean_opt_r3_epochs_9.joblib            0.091465   \n",
       "17   .\\model_mean_opt_r3_epochs_7.joblib            0.091553   \n",
       "15   .\\model_mean_opt_r3_epochs_5.joblib            0.091520   \n",
       "3   .\\model_mean_opt_r3_epochs_11.joblib            0.091532   \n",
       "16   .\\model_mean_opt_r3_epochs_6.joblib            0.091565   \n",
       "12   .\\model_mean_opt_r3_epochs_2.joblib            0.091729   \n",
       "9   .\\model_mean_opt_r3_epochs_17.joblib            0.091789   \n",
       "1    .\\model_mean_opt_r3_epochs_1.joblib            0.091836   \n",
       "4   .\\model_mean_opt_r3_epochs_12.joblib            0.091766   \n",
       "14   .\\model_mean_opt_r3_epochs_4.joblib            0.091819   \n",
       "10  .\\model_mean_opt_r3_epochs_18.joblib            0.091572   \n",
       "5   .\\model_mean_opt_r3_epochs_13.joblib            0.090951   \n",
       "\n",
       "    topographical_error  \n",
       "2              0.152431  \n",
       "8              0.152991  \n",
       "11             0.154454  \n",
       "18             0.154722  \n",
       "6              0.154843  \n",
       "13             0.156013  \n",
       "7              0.156452  \n",
       "0              0.156720  \n",
       "19             0.156890  \n",
       "17             0.157427  \n",
       "15             0.158036  \n",
       "3              0.158158  \n",
       "16             0.158426  \n",
       "12             0.158645  \n",
       "9              0.159035  \n",
       "1              0.159401  \n",
       "4              0.159937  \n",
       "14             0.160083  \n",
       "10             0.160229  \n",
       "5              0.160668  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for i, model_filepath in enumerate(models_pool_r3):\n",
    "    res.append({'model': model_filepath, 'topographical_error': e_top_r3[i], 'quantization_error': e_q_r3[i]})\n",
    "    #print(model_filepath)\n",
    "    #name.append(model_filepath[3:10])\n",
    "    #err_top.append(e_top[i])\n",
    "    #err_quant.append(e_q[i])\n",
    "\n",
    "results_df = pd.DataFrame(res)\n",
    "results_df.sort_values(['topographical_error'], ascending=True)\n",
    "#print(model_filepath,e_top[i],e_q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training...\n",
    " pca_linear_initialization took: 0.065000 seconds\n",
    " Rough training...\n",
    " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 39\n",
    " Finetune training...\n",
    " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 78              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_bmu': array([[  1.05000000e+02,   1.05000000e+02,   1.05000000e+02, ...,\n",
       "           8.62000000e+02,   8.62000000e+02,   8.62000000e+02],\n",
       "        [  1.65762096e+00,   1.67275687e+00,   1.68548998e+00, ...,\n",
       "           2.49997359e-02,   2.46383805e-02,   2.42878250e-02]]),\n",
       " '_component_names': [['SSS', 'SST', 'MLD', 'pCO2']],\n",
       " '_data': array([[ 0.18913603, -1.3459917 ,  3.41670057, -2.6790296 ],\n",
       "        [ 0.17588447, -1.3475531 ,  3.41021886, -2.69762985],\n",
       "        [ 0.15916678, -1.34988534,  3.38340523, -2.72281208],\n",
       "        ..., \n",
       "        [-0.84256275, -1.39285668, -0.15187448, -1.19543379],\n",
       "        [-0.84284339, -1.39285576, -0.15225229, -1.19487994],\n",
       "        [-0.84312895, -1.39285485, -0.15263131, -1.19433144]]),\n",
       " '_dim': 4L,\n",
       " '_distance_matrix': array([[  0.00000000e+00,   1.00000000e+00,   4.00000000e+00, ...,\n",
       "           1.80800000e+03,   1.87300000e+03,   1.94000000e+03],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "           1.74500000e+03,   1.80800000e+03,   1.87300000e+03],\n",
       "        [  4.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "           1.68400000e+03,   1.74500000e+03,   1.80800000e+03],\n",
       "        ..., \n",
       "        [  1.80800000e+03,   1.74500000e+03,   1.68400000e+03, ...,\n",
       "           0.00000000e+00,   1.00000000e+00,   4.00000000e+00],\n",
       "        [  1.87300000e+03,   1.80800000e+03,   1.74500000e+03, ...,\n",
       "           1.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "        [  1.94000000e+03,   1.87300000e+03,   1.80800000e+03, ...,\n",
       "           4.00000000e+00,   1.00000000e+00,   0.00000000e+00]]),\n",
       " '_dlabel': None,\n",
       " '_dlen': 41035L,\n",
       " '_normalizer': <sompy.normalization.VarianceNormalizer at 0x1ac8f780>,\n",
       " 'codebook': <sompy.codebook.Codebook at 0x1ab6df98>,\n",
       " 'data_raw': array([[ 0.18913603, -1.3459917 ,  3.41670057, -2.6790296 ],\n",
       "        [ 0.17588447, -1.3475531 ,  3.41021886, -2.69762985],\n",
       "        [ 0.15916678, -1.34988534,  3.38340523, -2.72281208],\n",
       "        ..., \n",
       "        [-0.84256275, -1.39285668, -0.15187448, -1.19543379],\n",
       "        [-0.84284339, -1.39285576, -0.15225229, -1.19487994],\n",
       "        [-0.84312895, -1.39285485, -0.15263131, -1.19433144]]),\n",
       " 'initialization': 'pca',\n",
       " 'mapshape': 'planar',\n",
       " 'mask': array([[ 1.,  1.,  1.,  1.]]),\n",
       " 'name': 'sompy',\n",
       " 'neighborhood': <sompy.neighborhood.GaussianNeighborhood at 0x1ab78748>,\n",
       " 'training': 'batch'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized = joblib.load('C:\\\\Users\\goyetc\\\\SOMPY\\\\model_mean_opt_r3_epochs_10.joblib')\n",
    "optimized.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " find_bmu took: 0.674000 seconds\n",
      " find_bmu took: 0.862000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1524308517119532"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized.calculate_topographic_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training...\n",
      " pca_linear_initialization took: 0.057000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.417000, quantization error: 0.945555\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.387000, quantization error: 0.746439\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.387000, quantization error: 0.623160\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.486000, quantization error: 0.599353\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.585753\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.393000, quantization error: 0.572083\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.499000, quantization error: 0.558950\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.545512\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.386000, quantization error: 0.532578\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.396000, quantization error: 0.520324\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.400000, quantization error: 0.508824\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.411000, quantization error: 0.498042\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.487598\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.417000, quantization error: 0.477290\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.395000, quantization error: 0.467370\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.396000, quantization error: 0.457675\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.401000, quantization error: 0.448045\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.408000, quantization error: 0.438046\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.493000, quantization error: 0.427855\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.509000, quantization error: 0.417180\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.503000, quantization error: 0.406167\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.507000, quantization error: 0.395391\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.387000, quantization error: 0.384663\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.485000, quantization error: 0.374184\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.479000, quantization error: 0.363820\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.475000, quantization error: 0.353474\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.403000, quantization error: 0.343073\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.586000, quantization error: 0.332645\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.390000, quantization error: 0.322258\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.426000, quantization error: 0.311768\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.439000, quantization error: 0.301187\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.426000, quantization error: 0.290691\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.546000, quantization error: 0.280193\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.414000, quantization error: 0.269777\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.489000, quantization error: 0.259459\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.412000, quantization error: 0.249142\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.496000, quantization error: 0.238938\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.228953\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.401000, quantization error: 0.219149\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.209597\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.402000, quantization error: 0.200214\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.198923\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.398000, quantization error: 0.197987\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.397000, quantization error: 0.197092\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.196179\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.507000, quantization error: 0.195422\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.391000, quantization error: 0.194769\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.194101\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.408000, quantization error: 0.193522\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.391000, quantization error: 0.193009\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.613000, quantization error: 0.192573\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.387000, quantization error: 0.192155\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.597000, quantization error: 0.191730\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.600000, quantization error: 0.191309\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.485000, quantization error: 0.190875\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.504000, quantization error: 0.190445\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.410000, quantization error: 0.190052\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.500000, quantization error: 0.189688\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.392000, quantization error: 0.189303\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.495000, quantization error: 0.188949\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.395000, quantization error: 0.188571\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.494000, quantization error: 0.188205\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.406000, quantization error: 0.187827\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.480000, quantization error: 0.187467\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.389000, quantization error: 0.187091\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.389000, quantization error: 0.186732\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.397000, quantization error: 0.186395\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.397000, quantization error: 0.186063\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.398000, quantization error: 0.185741\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.401000, quantization error: 0.185434\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.401000, quantization error: 0.185114\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.399000, quantization error: 0.184808\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.396000, quantization error: 0.184492\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.397000, quantization error: 0.184171\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.406000, quantization error: 0.183868\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.399000, quantization error: 0.183570\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.396000, quantization error: 0.183272\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.397000, quantization error: 0.182961\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.401000, quantization error: 0.182635\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.398000, quantization error: 0.182328\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.398000, quantization error: 0.182000\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.414000, quantization error: 0.181695\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.403000, quantization error: 0.181375\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.415000, quantization error: 0.181061\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.383000, quantization error: 0.180751\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.489000, quantization error: 0.180449\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.477000, quantization error: 0.180128\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.487000, quantization error: 0.179822\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.378000, quantization error: 0.179499\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.478000, quantization error: 0.179166\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.493000, quantization error: 0.178829\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.402000, quantization error: 0.178493\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.504000, quantization error: 0.178166\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.406000, quantization error: 0.177852\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.490000, quantization error: 0.177553\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.399000, quantization error: 0.177268\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.593000, quantization error: 0.176975\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.403000, quantization error: 0.176703\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.503000, quantization error: 0.176413\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.396000, quantization error: 0.176111\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.405000, quantization error: 0.175820\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.508000, quantization error: 0.175517\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.583000, quantization error: 0.175205\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.589000, quantization error: 0.174887\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.494000, quantization error: 0.174600\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.382000, quantization error: 0.174284\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.405000, quantization error: 0.173948\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.603000, quantization error: 0.173656\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.496000, quantization error: 0.173351\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.598000, quantization error: 0.173060\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.392000, quantization error: 0.172768\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.402000, quantization error: 0.172465\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.421000, quantization error: 0.172166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 74 ---> elapsed time:  0.519000, quantization error: 0.171854\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.393000, quantization error: 0.171559\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.600000, quantization error: 0.171246\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.614000, quantization error: 0.170948\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.604000, quantization error: 0.170631\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.507000, quantization error: 0.170313\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.496000, quantization error: 0.170004\n",
      "\n",
      " Final quantization error: 0.170004\n",
      " train took: 55.146000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.082000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.414000, quantization error: 0.920243\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.604000, quantization error: 0.677262\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.605000, quantization error: 0.599796\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.602000, quantization error: 0.569986\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.595000, quantization error: 0.551445\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.493000, quantization error: 0.537398\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.607000, quantization error: 0.525513\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.582000, quantization error: 0.514301\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.506000, quantization error: 0.503169\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.592000, quantization error: 0.492363\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.512000, quantization error: 0.482036\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.480000, quantization error: 0.471525\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.483000, quantization error: 0.461756\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.507000, quantization error: 0.452554\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.610000, quantization error: 0.444153\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.387000, quantization error: 0.435983\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.496000, quantization error: 0.428069\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.490000, quantization error: 0.420130\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.523000, quantization error: 0.412216\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.516000, quantization error: 0.404174\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.526000, quantization error: 0.396023\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.411000, quantization error: 0.387782\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.379374\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.491000, quantization error: 0.370937\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.498000, quantization error: 0.362344\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.403000, quantization error: 0.353465\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.600000, quantization error: 0.344302\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.415000, quantization error: 0.334983\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.510000, quantization error: 0.325358\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.595000, quantization error: 0.315540\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.508000, quantization error: 0.305549\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.481000, quantization error: 0.295380\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.391000, quantization error: 0.284994\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.405000, quantization error: 0.274628\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.516000, quantization error: 0.264208\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.399000, quantization error: 0.253651\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.502000, quantization error: 0.243107\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.409000, quantization error: 0.232585\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.506000, quantization error: 0.222228\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.495000, quantization error: 0.212217\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.401000, quantization error: 0.202230\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.491000, quantization error: 0.200684\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.407000, quantization error: 0.199449\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.533000, quantization error: 0.198498\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.496000, quantization error: 0.197691\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.486000, quantization error: 0.196982\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.393000, quantization error: 0.196333\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.401000, quantization error: 0.195831\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.404000, quantization error: 0.195358\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.401000, quantization error: 0.194870\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.516000, quantization error: 0.194377\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.407000, quantization error: 0.193951\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.402000, quantization error: 0.193545\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.413000, quantization error: 0.193171\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.396000, quantization error: 0.192767\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.488000, quantization error: 0.192370\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.191978\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.396000, quantization error: 0.191600\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.395000, quantization error: 0.191222\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.397000, quantization error: 0.190860\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.398000, quantization error: 0.190477\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.398000, quantization error: 0.190144\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.397000, quantization error: 0.189721\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.189289\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.398000, quantization error: 0.188814\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.397000, quantization error: 0.188372\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.398000, quantization error: 0.187941\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.398000, quantization error: 0.187520\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.397000, quantization error: 0.187090\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.397000, quantization error: 0.186711\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.399000, quantization error: 0.186342\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.397000, quantization error: 0.185997\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.399000, quantization error: 0.185616\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.398000, quantization error: 0.185232\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.397000, quantization error: 0.184827\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.184401\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.414000, quantization error: 0.184010\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.183639\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.397000, quantization error: 0.183266\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.414000, quantization error: 0.182928\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.397000, quantization error: 0.182595\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.415000, quantization error: 0.182247\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.397000, quantization error: 0.181915\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.396000, quantization error: 0.181584\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.411000, quantization error: 0.181238\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.399000, quantization error: 0.180942\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.415000, quantization error: 0.180651\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.415000, quantization error: 0.180342\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.421000, quantization error: 0.180038\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.399000, quantization error: 0.179733\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.401000, quantization error: 0.179430\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.394000, quantization error: 0.179130\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.397000, quantization error: 0.178824\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.397000, quantization error: 0.178520\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.398000, quantization error: 0.178240\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.395000, quantization error: 0.177918\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.417000, quantization error: 0.177589\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.397000, quantization error: 0.177291\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.395000, quantization error: 0.176989\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.414000, quantization error: 0.176677\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.396000, quantization error: 0.176375\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.397000, quantization error: 0.176057\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.401000, quantization error: 0.175771\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.393000, quantization error: 0.175461\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.397000, quantization error: 0.175148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 66 ---> elapsed time:  0.397000, quantization error: 0.174822\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.397000, quantization error: 0.174503\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.396000, quantization error: 0.174192\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.397000, quantization error: 0.173873\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.398000, quantization error: 0.173550\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.397000, quantization error: 0.173257\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.397000, quantization error: 0.172960\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.411000, quantization error: 0.172638\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.511000, quantization error: 0.172302\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.403000, quantization error: 0.172002\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.398000, quantization error: 0.171664\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.487000, quantization error: 0.171340\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.483000, quantization error: 0.170997\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.512000, quantization error: 0.170696\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.412000, quantization error: 0.170347\n",
      "\n",
      " Final quantization error: 0.170347\n",
      " train took: 54.899000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.056000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.388000, quantization error: 0.876865\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.517000, quantization error: 0.648043\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.421000, quantization error: 0.586466\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.407000, quantization error: 0.563995\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.395000, quantization error: 0.549131\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.523000, quantization error: 0.538403\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.418000, quantization error: 0.527562\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.411000, quantization error: 0.516408\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.397000, quantization error: 0.506272\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.412000, quantization error: 0.496606\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.487335\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.414000, quantization error: 0.478573\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.397000, quantization error: 0.469941\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.396000, quantization error: 0.461246\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.398000, quantization error: 0.452393\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.401000, quantization error: 0.444019\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.435718\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.401000, quantization error: 0.427428\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.507000, quantization error: 0.419126\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.499000, quantization error: 0.410653\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.480000, quantization error: 0.402067\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.407000, quantization error: 0.393392\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.390000, quantization error: 0.384513\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.404000, quantization error: 0.375418\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.501000, quantization error: 0.366121\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.521000, quantization error: 0.356540\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.417000, quantization error: 0.346928\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.388000, quantization error: 0.336994\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.407000, quantization error: 0.326847\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.387000, quantization error: 0.316839\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.479000, quantization error: 0.306738\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.411000, quantization error: 0.296529\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.412000, quantization error: 0.286132\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.396000, quantization error: 0.275662\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.422000, quantization error: 0.265174\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.410000, quantization error: 0.254739\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.412000, quantization error: 0.244143\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.411000, quantization error: 0.233849\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.409000, quantization error: 0.223635\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.412000, quantization error: 0.213238\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.423000, quantization error: 0.202979\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.412000, quantization error: 0.201403\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.414000, quantization error: 0.200347\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.412000, quantization error: 0.199413\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.411000, quantization error: 0.198677\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.412000, quantization error: 0.197956\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.400000, quantization error: 0.197219\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.196590\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.398000, quantization error: 0.196017\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.399000, quantization error: 0.195471\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.403000, quantization error: 0.194927\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.385000, quantization error: 0.194427\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.389000, quantization error: 0.193868\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.396000, quantization error: 0.193304\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.399000, quantization error: 0.192697\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.398000, quantization error: 0.192114\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.397000, quantization error: 0.191519\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.399000, quantization error: 0.190965\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.399000, quantization error: 0.190467\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.398000, quantization error: 0.190022\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.396000, quantization error: 0.189614\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.397000, quantization error: 0.189221\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.413000, quantization error: 0.188836\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.395000, quantization error: 0.188449\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.398000, quantization error: 0.188098\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.398000, quantization error: 0.187710\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.397000, quantization error: 0.187317\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.398000, quantization error: 0.186908\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.413000, quantization error: 0.186499\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.396000, quantization error: 0.186129\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.397000, quantization error: 0.185777\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.397000, quantization error: 0.185400\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.398000, quantization error: 0.184975\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.402000, quantization error: 0.184607\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.397000, quantization error: 0.184200\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.183806\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.400000, quantization error: 0.183458\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.183089\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.391000, quantization error: 0.182754\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.404000, quantization error: 0.182391\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.397000, quantization error: 0.182013\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.398000, quantization error: 0.181648\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.395000, quantization error: 0.181310\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.402000, quantization error: 0.180968\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.397000, quantization error: 0.180607\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.399000, quantization error: 0.180252\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.397000, quantization error: 0.179915\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.397000, quantization error: 0.179550\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.413000, quantization error: 0.179172\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.396000, quantization error: 0.178816\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.400000, quantization error: 0.178466\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.413000, quantization error: 0.178104\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.398000, quantization error: 0.177779\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.396000, quantization error: 0.177441\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.398000, quantization error: 0.177099\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.397000, quantization error: 0.176754\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.398000, quantization error: 0.176402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 58 ---> elapsed time:  0.399000, quantization error: 0.176049\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.395000, quantization error: 0.175726\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.398000, quantization error: 0.175380\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.396000, quantization error: 0.175036\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.399000, quantization error: 0.174696\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.416000, quantization error: 0.174355\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.397000, quantization error: 0.174038\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.400000, quantization error: 0.173686\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.397000, quantization error: 0.173323\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.397000, quantization error: 0.172951\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.401000, quantization error: 0.172620\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.399000, quantization error: 0.172290\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.404000, quantization error: 0.171965\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.398000, quantization error: 0.171626\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.398000, quantization error: 0.171281\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.398000, quantization error: 0.170948\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.397000, quantization error: 0.170611\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.399000, quantization error: 0.170279\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.395000, quantization error: 0.169962\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.400000, quantization error: 0.169639\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.411000, quantization error: 0.169336\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.396000, quantization error: 0.169026\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.398000, quantization error: 0.168706\n",
      "\n",
      " Final quantization error: 0.168706\n",
      " train took: 50.787000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.045000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.391000, quantization error: 0.863685\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.678312\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.398000, quantization error: 0.587071\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.413000, quantization error: 0.572774\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.398000, quantization error: 0.563153\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.401000, quantization error: 0.554712\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.412000, quantization error: 0.546671\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.413000, quantization error: 0.538866\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.397000, quantization error: 0.531049\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.395000, quantization error: 0.523380\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.399000, quantization error: 0.515512\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.398000, quantization error: 0.507404\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.413000, quantization error: 0.499257\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.398000, quantization error: 0.490838\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.398000, quantization error: 0.482209\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.401000, quantization error: 0.473580\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.398000, quantization error: 0.465019\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.397000, quantization error: 0.456524\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.402000, quantization error: 0.447932\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.400000, quantization error: 0.439384\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.399000, quantization error: 0.430913\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.509000, quantization error: 0.422317\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.403000, quantization error: 0.413637\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.397000, quantization error: 0.404806\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.397000, quantization error: 0.395755\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.398000, quantization error: 0.386400\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.399000, quantization error: 0.376846\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.399000, quantization error: 0.366633\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.395000, quantization error: 0.355577\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.399000, quantization error: 0.344091\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.397000, quantization error: 0.332535\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.398000, quantization error: 0.321146\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.398000, quantization error: 0.309937\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.396000, quantization error: 0.298764\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.407000, quantization error: 0.287512\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.406000, quantization error: 0.276128\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.396000, quantization error: 0.264837\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.389000, quantization error: 0.253627\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.392000, quantization error: 0.242529\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.397000, quantization error: 0.231767\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.394000, quantization error: 0.220550\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.394000, quantization error: 0.218457\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.397000, quantization error: 0.216956\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.398000, quantization error: 0.215795\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.396000, quantization error: 0.214978\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.415000, quantization error: 0.214145\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.402000, quantization error: 0.213484\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.393000, quantization error: 0.212767\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.212093\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.521000, quantization error: 0.211508\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.512000, quantization error: 0.210984\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.386000, quantization error: 0.210401\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.403000, quantization error: 0.209897\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.399000, quantization error: 0.209449\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.413000, quantization error: 0.209045\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.413000, quantization error: 0.208617\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.397000, quantization error: 0.208214\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.397000, quantization error: 0.207798\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.413000, quantization error: 0.207373\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.399000, quantization error: 0.206929\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.399000, quantization error: 0.206521\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.412000, quantization error: 0.206169\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.412000, quantization error: 0.205821\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.397000, quantization error: 0.205429\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.413000, quantization error: 0.205046\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.204688\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.397000, quantization error: 0.204317\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.397000, quantization error: 0.203960\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.397000, quantization error: 0.203550\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.398000, quantization error: 0.203175\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.413000, quantization error: 0.202819\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.397000, quantization error: 0.202436\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.397000, quantization error: 0.202056\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.413000, quantization error: 0.201685\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.413000, quantization error: 0.201332\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.396000, quantization error: 0.200981\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.428000, quantization error: 0.200643\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.398000, quantization error: 0.200301\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.396000, quantization error: 0.199963\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.413000, quantization error: 0.199618\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.411000, quantization error: 0.199280\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.398000, quantization error: 0.198934\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.398000, quantization error: 0.198492\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.411000, quantization error: 0.198116\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.397000, quantization error: 0.197712\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.397000, quantization error: 0.197312\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.398000, quantization error: 0.196950\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.397000, quantization error: 0.196610\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.396000, quantization error: 0.196284\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 50 ---> elapsed time:  0.397000, quantization error: 0.195937\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.397000, quantization error: 0.195614\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.413000, quantization error: 0.195262\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.396000, quantization error: 0.194926\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.396000, quantization error: 0.194563\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.513000, quantization error: 0.194240\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.420000, quantization error: 0.193890\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.407000, quantization error: 0.193563\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.393000, quantization error: 0.193162\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.498000, quantization error: 0.192720\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.397000, quantization error: 0.192302\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.398000, quantization error: 0.191921\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.395000, quantization error: 0.191541\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.398000, quantization error: 0.191174\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.398000, quantization error: 0.190807\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.395000, quantization error: 0.190478\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.494000, quantization error: 0.190148\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.411000, quantization error: 0.189829\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.515000, quantization error: 0.189506\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.507000, quantization error: 0.189193\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.489000, quantization error: 0.188849\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.506000, quantization error: 0.188525\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.499000, quantization error: 0.188166\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.392000, quantization error: 0.187820\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.406000, quantization error: 0.187487\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.475000, quantization error: 0.187150\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.493000, quantization error: 0.186815\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.490000, quantization error: 0.186461\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.492000, quantization error: 0.186081\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.493000, quantization error: 0.185664\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.502000, quantization error: 0.185288\n",
      "\n",
      " Final quantization error: 0.185288\n",
      " train took: 51.670000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.054000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.419000, quantization error: 1.033150\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.408000, quantization error: 0.795718\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.520000, quantization error: 0.660954\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.525000, quantization error: 0.625487\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.532000, quantization error: 0.608021\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.529000, quantization error: 0.597750\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.504000, quantization error: 0.588882\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.500000, quantization error: 0.580183\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.499000, quantization error: 0.571804\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.528000, quantization error: 0.563344\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.513000, quantization error: 0.555034\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.401000, quantization error: 0.546665\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.417000, quantization error: 0.538188\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.393000, quantization error: 0.529619\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.510000, quantization error: 0.520816\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.409000, quantization error: 0.511746\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.593000, quantization error: 0.502356\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.617000, quantization error: 0.493516\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.525000, quantization error: 0.484970\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.519000, quantization error: 0.476532\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.523000, quantization error: 0.467989\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.508000, quantization error: 0.459318\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.550000, quantization error: 0.450613\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.393000, quantization error: 0.441797\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.591000, quantization error: 0.432707\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.509000, quantization error: 0.423637\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.402000, quantization error: 0.414406\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.511000, quantization error: 0.404975\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.588000, quantization error: 0.395197\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.480000, quantization error: 0.385294\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.391000, quantization error: 0.375330\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.397000, quantization error: 0.364980\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.405000, quantization error: 0.354211\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.486000, quantization error: 0.343242\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.404000, quantization error: 0.332066\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.404000, quantization error: 0.320688\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.378000, quantization error: 0.308948\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.296973\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.398000, quantization error: 0.284929\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.273096\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.400000, quantization error: 0.261228\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.403000, quantization error: 0.259327\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.377000, quantization error: 0.258119\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.383000, quantization error: 0.257078\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.504000, quantization error: 0.256181\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.396000, quantization error: 0.255298\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.389000, quantization error: 0.254144\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.405000, quantization error: 0.253322\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.397000, quantization error: 0.252524\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.391000, quantization error: 0.251811\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.396000, quantization error: 0.251210\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.388000, quantization error: 0.250643\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.396000, quantization error: 0.250107\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.414000, quantization error: 0.249586\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.407000, quantization error: 0.249093\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.406000, quantization error: 0.248596\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.395000, quantization error: 0.248080\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.495000, quantization error: 0.247507\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.493000, quantization error: 0.247038\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.401000, quantization error: 0.246510\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.393000, quantization error: 0.246016\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.372000, quantization error: 0.245582\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.399000, quantization error: 0.245140\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.403000, quantization error: 0.244334\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.391000, quantization error: 0.243449\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.496000, quantization error: 0.242865\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.500000, quantization error: 0.242346\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.416000, quantization error: 0.241805\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.417000, quantization error: 0.241370\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.390000, quantization error: 0.240928\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.394000, quantization error: 0.240510\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.511000, quantization error: 0.240067\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.403000, quantization error: 0.239673\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.412000, quantization error: 0.239236\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.411000, quantization error: 0.238803\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.399000, quantization error: 0.238375\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.396000, quantization error: 0.237883\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.237412\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.398000, quantization error: 0.236976\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.399000, quantization error: 0.236561\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.395000, quantization error: 0.236095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 42 ---> elapsed time:  0.399000, quantization error: 0.235665\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.394000, quantization error: 0.235241\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.398000, quantization error: 0.234807\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.497000, quantization error: 0.234425\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.402000, quantization error: 0.234014\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.406000, quantization error: 0.233601\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.399000, quantization error: 0.233200\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.398000, quantization error: 0.232796\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.396000, quantization error: 0.232388\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.393000, quantization error: 0.231970\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.412000, quantization error: 0.231571\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.407000, quantization error: 0.231134\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.426000, quantization error: 0.230694\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.397000, quantization error: 0.230281\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.404000, quantization error: 0.229847\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.395000, quantization error: 0.229464\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.395000, quantization error: 0.229043\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.402000, quantization error: 0.228633\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.592000, quantization error: 0.228218\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.505000, quantization error: 0.227819\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.505000, quantization error: 0.227438\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.431000, quantization error: 0.227048\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.514000, quantization error: 0.226671\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.413000, quantization error: 0.226296\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.405000, quantization error: 0.225910\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.400000, quantization error: 0.225533\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.494000, quantization error: 0.225169\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.401000, quantization error: 0.224781\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.393000, quantization error: 0.224431\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.389000, quantization error: 0.224060\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.494000, quantization error: 0.223696\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.406000, quantization error: 0.223340\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.538000, quantization error: 0.223001\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.519000, quantization error: 0.222624\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.511000, quantization error: 0.222280\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.518000, quantization error: 0.221931\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.492000, quantization error: 0.221570\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.473000, quantization error: 0.221215\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.489000, quantization error: 0.220841\n",
      "\n",
      " Final quantization error: 0.220841\n",
      " train took: 54.417000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.056000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.480000, quantization error: 0.904903\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.395000, quantization error: 0.667796\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.421000, quantization error: 0.588251\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.496000, quantization error: 0.568545\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.403000, quantization error: 0.552687\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.419000, quantization error: 0.541847\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.411000, quantization error: 0.532269\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.384000, quantization error: 0.523059\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.514078\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.412000, quantization error: 0.505080\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.395000, quantization error: 0.495839\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.503000, quantization error: 0.486895\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.504000, quantization error: 0.477912\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.527000, quantization error: 0.469107\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.423000, quantization error: 0.460169\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.515000, quantization error: 0.451090\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.504000, quantization error: 0.441822\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.509000, quantization error: 0.432524\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.406000, quantization error: 0.423106\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.405000, quantization error: 0.413353\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.489000, quantization error: 0.403475\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.491000, quantization error: 0.393570\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.496000, quantization error: 0.383806\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.514000, quantization error: 0.373965\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.493000, quantization error: 0.364189\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.414000, quantization error: 0.354479\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.414000, quantization error: 0.344664\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.522000, quantization error: 0.334835\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.500000, quantization error: 0.325159\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.406000, quantization error: 0.315510\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.404000, quantization error: 0.305842\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.508000, quantization error: 0.296322\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.515000, quantization error: 0.286904\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.509000, quantization error: 0.277498\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.392000, quantization error: 0.268115\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.405000, quantization error: 0.258764\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.405000, quantization error: 0.249408\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.492000, quantization error: 0.240148\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.403000, quantization error: 0.230904\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.500000, quantization error: 0.221652\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.509000, quantization error: 0.212392\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.400000, quantization error: 0.211042\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.497000, quantization error: 0.210302\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.398000, quantization error: 0.209664\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.374000, quantization error: 0.209192\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.491000, quantization error: 0.208746\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.384000, quantization error: 0.208328\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.396000, quantization error: 0.207960\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.411000, quantization error: 0.207613\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.414000, quantization error: 0.207263\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.536000, quantization error: 0.206927\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.518000, quantization error: 0.206590\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.608000, quantization error: 0.206257\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.413000, quantization error: 0.205919\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.516000, quantization error: 0.205578\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.402000, quantization error: 0.205234\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.492000, quantization error: 0.204880\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.505000, quantization error: 0.204539\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.494000, quantization error: 0.204216\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.498000, quantization error: 0.203931\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.499000, quantization error: 0.203628\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.492000, quantization error: 0.203307\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.398000, quantization error: 0.203009\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.493000, quantization error: 0.202710\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.401000, quantization error: 0.202406\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.398000, quantization error: 0.202115\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.505000, quantization error: 0.201813\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.418000, quantization error: 0.201494\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.602000, quantization error: 0.201201\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.512000, quantization error: 0.200889\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.493000, quantization error: 0.200603\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.489000, quantization error: 0.200307\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.490000, quantization error: 0.199982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 34 ---> elapsed time:  0.393000, quantization error: 0.199689\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.388000, quantization error: 0.199411\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.498000, quantization error: 0.199131\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.509000, quantization error: 0.198825\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.407000, quantization error: 0.198503\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.486000, quantization error: 0.198210\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.528000, quantization error: 0.197896\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.398000, quantization error: 0.197579\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.503000, quantization error: 0.197281\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.708000, quantization error: 0.196972\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.500000, quantization error: 0.196658\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.608000, quantization error: 0.196335\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.541000, quantization error: 0.196045\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.619000, quantization error: 0.195734\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.507000, quantization error: 0.195420\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.481000, quantization error: 0.195106\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.495000, quantization error: 0.194800\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.390000, quantization error: 0.194491\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.504000, quantization error: 0.194200\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.500000, quantization error: 0.193910\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.497000, quantization error: 0.193615\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.491000, quantization error: 0.193303\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.393000, quantization error: 0.193000\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.394000, quantization error: 0.192702\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.497000, quantization error: 0.192391\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.386000, quantization error: 0.192078\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.481000, quantization error: 0.191769\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.499000, quantization error: 0.191430\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.397000, quantization error: 0.191094\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.399000, quantization error: 0.190771\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.395000, quantization error: 0.190430\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.497000, quantization error: 0.190119\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.390000, quantization error: 0.189816\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.407000, quantization error: 0.189481\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.503000, quantization error: 0.189159\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.389000, quantization error: 0.188844\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.488000, quantization error: 0.188529\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.502000, quantization error: 0.188161\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.504000, quantization error: 0.187793\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.512000, quantization error: 0.187452\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.411000, quantization error: 0.187126\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.418000, quantization error: 0.186777\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.416000, quantization error: 0.186428\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.396000, quantization error: 0.186097\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.492000, quantization error: 0.185741\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.621000, quantization error: 0.185402\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.499000, quantization error: 0.185098\n",
      "\n",
      " Final quantization error: 0.185098\n",
      " train took: 56.857000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.069000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.490000, quantization error: 0.841313\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.503000, quantization error: 0.587115\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.495000, quantization error: 0.475844\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.516000, quantization error: 0.451019\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.400000, quantization error: 0.443376\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.492000, quantization error: 0.436398\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.503000, quantization error: 0.429589\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.402000, quantization error: 0.422576\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.499000, quantization error: 0.415665\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.394000, quantization error: 0.408801\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.512000, quantization error: 0.401877\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.495000, quantization error: 0.395033\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.408000, quantization error: 0.388250\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.514000, quantization error: 0.381419\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.515000, quantization error: 0.374597\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.407000, quantization error: 0.367661\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.401000, quantization error: 0.360678\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.418000, quantization error: 0.353697\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.412000, quantization error: 0.346578\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.589000, quantization error: 0.339414\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.403000, quantization error: 0.332063\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.502000, quantization error: 0.324913\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.509000, quantization error: 0.317823\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.398000, quantization error: 0.310696\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.487000, quantization error: 0.303599\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.502000, quantization error: 0.296292\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.477000, quantization error: 0.288839\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.408000, quantization error: 0.281265\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.421000, quantization error: 0.273681\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.505000, quantization error: 0.265689\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.419000, quantization error: 0.257523\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.403000, quantization error: 0.249247\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.395000, quantization error: 0.241019\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.404000, quantization error: 0.232796\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.393000, quantization error: 0.224501\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.388000, quantization error: 0.216152\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.389000, quantization error: 0.207904\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.488000, quantization error: 0.199637\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.508000, quantization error: 0.191456\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.500000, quantization error: 0.183472\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.410000, quantization error: 0.175799\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.487000, quantization error: 0.174687\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.495000, quantization error: 0.173814\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.410000, quantization error: 0.173160\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.390000, quantization error: 0.172555\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.397000, quantization error: 0.171980\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.490000, quantization error: 0.171465\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.504000, quantization error: 0.170980\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.493000, quantization error: 0.170533\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.511000, quantization error: 0.170084\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.169680\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.386000, quantization error: 0.169293\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.404000, quantization error: 0.168957\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.503000, quantization error: 0.168626\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.495000, quantization error: 0.168296\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.484000, quantization error: 0.167999\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.500000, quantization error: 0.167716\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.482000, quantization error: 0.167446\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.405000, quantization error: 0.167153\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.491000, quantization error: 0.166845\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.498000, quantization error: 0.166540\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.391000, quantization error: 0.166243\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.387000, quantization error: 0.165967\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.504000, quantization error: 0.165682\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.395000, quantization error: 0.165391\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 26 ---> elapsed time:  0.382000, quantization error: 0.165107\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.401000, quantization error: 0.164818\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.414000, quantization error: 0.164535\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.497000, quantization error: 0.164257\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.402000, quantization error: 0.163987\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.516000, quantization error: 0.163714\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.495000, quantization error: 0.163434\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.408000, quantization error: 0.163200\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.425000, quantization error: 0.162940\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.496000, quantization error: 0.162674\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.404000, quantization error: 0.162429\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.494000, quantization error: 0.162155\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.393000, quantization error: 0.161889\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.389000, quantization error: 0.161623\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.396000, quantization error: 0.161373\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.482000, quantization error: 0.161124\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.492000, quantization error: 0.160864\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.505000, quantization error: 0.160601\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.515000, quantization error: 0.160348\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.519000, quantization error: 0.160070\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.411000, quantization error: 0.159805\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.414000, quantization error: 0.159538\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.507000, quantization error: 0.159268\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.497000, quantization error: 0.158975\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.509000, quantization error: 0.158711\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.500000, quantization error: 0.158417\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.405000, quantization error: 0.158173\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.403000, quantization error: 0.157878\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.502000, quantization error: 0.157629\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.407000, quantization error: 0.157397\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.485000, quantization error: 0.157118\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.398000, quantization error: 0.156848\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.379000, quantization error: 0.156603\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.404000, quantization error: 0.156345\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.415000, quantization error: 0.156092\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.396000, quantization error: 0.155837\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.493000, quantization error: 0.155562\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.497000, quantization error: 0.155274\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.492000, quantization error: 0.155018\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.501000, quantization error: 0.154756\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.699000, quantization error: 0.154488\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.394000, quantization error: 0.154235\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.492000, quantization error: 0.153998\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.502000, quantization error: 0.153720\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.503000, quantization error: 0.153441\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.386000, quantization error: 0.153179\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.516000, quantization error: 0.152928\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.601000, quantization error: 0.152695\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.595000, quantization error: 0.152469\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.576000, quantization error: 0.152243\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.490000, quantization error: 0.152004\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.493000, quantization error: 0.151757\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.504000, quantization error: 0.151508\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.403000, quantization error: 0.151246\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.412000, quantization error: 0.150994\n",
      "\n",
      " Final quantization error: 0.150994\n",
      " train took: 56.186000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.061000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.400000, quantization error: 0.837110\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.489000, quantization error: 0.536594\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.524000, quantization error: 0.457915\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.496000, quantization error: 0.440310\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.494000, quantization error: 0.431417\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.526000, quantization error: 0.422942\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.540000, quantization error: 0.415250\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.503000, quantization error: 0.407690\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.511000, quantization error: 0.400238\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.501000, quantization error: 0.392822\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.393000, quantization error: 0.385487\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.395000, quantization error: 0.378037\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.429000, quantization error: 0.370687\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.481000, quantization error: 0.363268\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.413000, quantization error: 0.355980\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.409000, quantization error: 0.348685\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.399000, quantization error: 0.341419\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.505000, quantization error: 0.334217\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.387000, quantization error: 0.327076\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.484000, quantization error: 0.319979\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.409000, quantization error: 0.312998\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.404000, quantization error: 0.306037\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.378000, quantization error: 0.299101\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.503000, quantization error: 0.292162\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.390000, quantization error: 0.285088\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.491000, quantization error: 0.277956\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.402000, quantization error: 0.270914\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.416000, quantization error: 0.263862\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.397000, quantization error: 0.256772\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.502000, quantization error: 0.249755\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.399000, quantization error: 0.242574\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.373000, quantization error: 0.235211\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.394000, quantization error: 0.227851\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.493000, quantization error: 0.220579\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.405000, quantization error: 0.213370\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.496000, quantization error: 0.206187\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.404000, quantization error: 0.198932\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.492000, quantization error: 0.191659\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.494000, quantization error: 0.184484\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.401000, quantization error: 0.177334\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.403000, quantization error: 0.170125\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.412000, quantization error: 0.168963\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.396000, quantization error: 0.168144\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.400000, quantization error: 0.167490\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.403000, quantization error: 0.166961\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.389000, quantization error: 0.166469\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.412000, quantization error: 0.166089\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.387000, quantization error: 0.165697\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.396000, quantization error: 0.165373\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.412000, quantization error: 0.165040\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.398000, quantization error: 0.164737\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.390000, quantization error: 0.164431\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.494000, quantization error: 0.164147\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.407000, quantization error: 0.163886\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.533000, quantization error: 0.163629\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.407000, quantization error: 0.163381\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.506000, quantization error: 0.163066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 18 ---> elapsed time:  0.512000, quantization error: 0.162769\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.529000, quantization error: 0.162483\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.404000, quantization error: 0.162203\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.399000, quantization error: 0.161934\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.413000, quantization error: 0.161669\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.411000, quantization error: 0.161390\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.414000, quantization error: 0.161127\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.393000, quantization error: 0.160839\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.420000, quantization error: 0.160564\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.399000, quantization error: 0.160300\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.402000, quantization error: 0.160033\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.421000, quantization error: 0.159786\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.518000, quantization error: 0.159515\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.580000, quantization error: 0.159259\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.611000, quantization error: 0.159008\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.493000, quantization error: 0.158765\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.404000, quantization error: 0.158512\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.412000, quantization error: 0.158249\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.629000, quantization error: 0.157991\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.516000, quantization error: 0.157741\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.410000, quantization error: 0.157509\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.395000, quantization error: 0.157263\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.414000, quantization error: 0.157024\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.517000, quantization error: 0.156764\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.412000, quantization error: 0.156521\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.614000, quantization error: 0.156287\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.409000, quantization error: 0.156060\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.413000, quantization error: 0.155838\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.408000, quantization error: 0.155609\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.617000, quantization error: 0.155371\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.420000, quantization error: 0.155142\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.408000, quantization error: 0.154895\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.498000, quantization error: 0.154630\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.408000, quantization error: 0.154387\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.397000, quantization error: 0.154131\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.396000, quantization error: 0.153900\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.490000, quantization error: 0.153669\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.407000, quantization error: 0.153423\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.497000, quantization error: 0.153189\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.398000, quantization error: 0.152959\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.395000, quantization error: 0.152730\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.398000, quantization error: 0.152503\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.507000, quantization error: 0.152266\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.516000, quantization error: 0.152058\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.517000, quantization error: 0.151844\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.534000, quantization error: 0.151629\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.479000, quantization error: 0.151420\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.493000, quantization error: 0.151207\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.603000, quantization error: 0.150990\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.615000, quantization error: 0.150763\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.515000, quantization error: 0.150545\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.506000, quantization error: 0.150334\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.389000, quantization error: 0.150098\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.390000, quantization error: 0.149862\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.500000, quantization error: 0.149636\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.492000, quantization error: 0.149412\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.493000, quantization error: 0.149198\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.495000, quantization error: 0.148989\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.495000, quantization error: 0.148767\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.492000, quantization error: 0.148536\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.495000, quantization error: 0.148302\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.499000, quantization error: 0.148070\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.491000, quantization error: 0.147827\n",
      "\n",
      " Final quantization error: 0.147827\n",
      " train took: 55.678000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.064000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.488000, quantization error: 0.851469\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.401000, quantization error: 0.550554\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.496000, quantization error: 0.484532\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.400000, quantization error: 0.468414\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.407000, quantization error: 0.458293\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.394000, quantization error: 0.448577\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.405000, quantization error: 0.439480\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.425000, quantization error: 0.431149\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.503000, quantization error: 0.423184\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.506000, quantization error: 0.415264\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.502000, quantization error: 0.407397\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.504000, quantization error: 0.399612\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.399000, quantization error: 0.391995\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.388000, quantization error: 0.384444\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.498000, quantization error: 0.376953\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.394000, quantization error: 0.369580\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.509000, quantization error: 0.362201\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.405000, quantization error: 0.354773\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.397000, quantization error: 0.347328\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.399000, quantization error: 0.339861\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.491000, quantization error: 0.332304\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.408000, quantization error: 0.324769\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.492000, quantization error: 0.317194\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.492000, quantization error: 0.309480\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.387000, quantization error: 0.301789\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.498000, quantization error: 0.294050\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.487000, quantization error: 0.286174\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.396000, quantization error: 0.278359\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.494000, quantization error: 0.270604\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.518000, quantization error: 0.262736\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.393000, quantization error: 0.255004\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.405000, quantization error: 0.247093\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.411000, quantization error: 0.239220\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.410000, quantization error: 0.231344\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.487000, quantization error: 0.223587\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.395000, quantization error: 0.216019\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.397000, quantization error: 0.208469\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.485000, quantization error: 0.200803\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.495000, quantization error: 0.193246\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.495000, quantization error: 0.185743\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.423000, quantization error: 0.178336\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.506000, quantization error: 0.177151\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.502000, quantization error: 0.176300\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.394000, quantization error: 0.175644\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.399000, quantization error: 0.175075\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.385000, quantization error: 0.174568\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.490000, quantization error: 0.174131\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.385000, quantization error: 0.173687\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.375000, quantization error: 0.173326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 10 ---> elapsed time:  0.488000, quantization error: 0.172969\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.495000, quantization error: 0.172600\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.417000, quantization error: 0.172276\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.415000, quantization error: 0.171946\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.486000, quantization error: 0.171610\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.489000, quantization error: 0.171275\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.416000, quantization error: 0.170938\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.485000, quantization error: 0.170663\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.487000, quantization error: 0.170373\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.488000, quantization error: 0.170089\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.513000, quantization error: 0.169802\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.415000, quantization error: 0.169521\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.388000, quantization error: 0.169206\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.395000, quantization error: 0.168873\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.401000, quantization error: 0.168540\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.492000, quantization error: 0.168255\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.411000, quantization error: 0.168010\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.400000, quantization error: 0.167764\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.497000, quantization error: 0.167515\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.497000, quantization error: 0.167272\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.397000, quantization error: 0.167027\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.425000, quantization error: 0.166800\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.385000, quantization error: 0.166580\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.402000, quantization error: 0.166356\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.401000, quantization error: 0.166123\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.496000, quantization error: 0.165898\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.490000, quantization error: 0.165676\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.501000, quantization error: 0.165445\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.479000, quantization error: 0.165206\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.405000, quantization error: 0.164974\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.382000, quantization error: 0.164731\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.503000, quantization error: 0.164478\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.495000, quantization error: 0.164228\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.597000, quantization error: 0.163969\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.599000, quantization error: 0.163712\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.505000, quantization error: 0.163473\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.493000, quantization error: 0.163225\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.393000, quantization error: 0.162962\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.493000, quantization error: 0.162737\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.603000, quantization error: 0.162504\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.626000, quantization error: 0.162269\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.499000, quantization error: 0.162043\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.492000, quantization error: 0.161785\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.608000, quantization error: 0.161545\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.514000, quantization error: 0.161316\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.507000, quantization error: 0.161072\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.499000, quantization error: 0.160836\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.514000, quantization error: 0.160583\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.445000, quantization error: 0.160351\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.409000, quantization error: 0.160123\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.387000, quantization error: 0.159870\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.490000, quantization error: 0.159618\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.491000, quantization error: 0.159383\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.389000, quantization error: 0.159121\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.391000, quantization error: 0.158881\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.387000, quantization error: 0.158632\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.391000, quantization error: 0.158391\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.492000, quantization error: 0.158161\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.490000, quantization error: 0.157927\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.494000, quantization error: 0.157699\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.498000, quantization error: 0.157474\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.489000, quantization error: 0.157233\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.504000, quantization error: 0.157019\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.498000, quantization error: 0.156805\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.505000, quantization error: 0.156576\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.423000, quantization error: 0.156353\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.410000, quantization error: 0.156111\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.411000, quantization error: 0.155866\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.394000, quantization error: 0.155639\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.501000, quantization error: 0.155406\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.494000, quantization error: 0.155152\n",
      "\n",
      " Final quantization error: 0.155152\n",
      " train took: 55.778000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.071000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.401000, quantization error: 0.880284\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.501000, quantization error: 0.657021\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.498000, quantization error: 0.557818\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.400000, quantization error: 0.532774\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.497000, quantization error: 0.520543\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.505000, quantization error: 0.509914\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.481000, quantization error: 0.500811\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.493000, quantization error: 0.492577\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.501000, quantization error: 0.484681\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.511000, quantization error: 0.476777\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.494000, quantization error: 0.469021\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.394000, quantization error: 0.461324\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.493000, quantization error: 0.453702\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.504000, quantization error: 0.446093\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.408000, quantization error: 0.438338\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.502000, quantization error: 0.430502\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.411000, quantization error: 0.422631\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.509000, quantization error: 0.414893\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.402000, quantization error: 0.407135\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.498000, quantization error: 0.399216\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.493000, quantization error: 0.391035\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.510000, quantization error: 0.382774\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.391000, quantization error: 0.374467\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.508000, quantization error: 0.366050\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.403000, quantization error: 0.357528\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.401000, quantization error: 0.348937\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.397000, quantization error: 0.340327\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.489000, quantization error: 0.331606\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.402000, quantization error: 0.322730\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.484000, quantization error: 0.313639\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.498000, quantization error: 0.304587\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.483000, quantization error: 0.295650\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.493000, quantization error: 0.286614\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.489000, quantization error: 0.277335\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.496000, quantization error: 0.268025\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.499000, quantization error: 0.258555\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.514000, quantization error: 0.249179\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.396000, quantization error: 0.239773\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.505000, quantization error: 0.230720\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.489000, quantization error: 0.221598\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.386000, quantization error: 0.212566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 2 ---> elapsed time:  0.491000, quantization error: 0.210913\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.477000, quantization error: 0.209846\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.487000, quantization error: 0.209042\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.500000, quantization error: 0.208135\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.477000, quantization error: 0.207317\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.497000, quantization error: 0.206706\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.399000, quantization error: 0.206271\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.502000, quantization error: 0.205920\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.494000, quantization error: 0.205494\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.481000, quantization error: 0.204975\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.507000, quantization error: 0.204511\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.417000, quantization error: 0.204079\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.413000, quantization error: 0.203684\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.422000, quantization error: 0.203328\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.489000, quantization error: 0.202952\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.484000, quantization error: 0.202616\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.502000, quantization error: 0.202251\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.496000, quantization error: 0.201940\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.400000, quantization error: 0.201635\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.392000, quantization error: 0.201299\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.482000, quantization error: 0.200985\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.495000, quantization error: 0.200693\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.402000, quantization error: 0.200394\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.433000, quantization error: 0.200070\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.502000, quantization error: 0.199770\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.498000, quantization error: 0.199450\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.412000, quantization error: 0.199104\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.402000, quantization error: 0.198801\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.396000, quantization error: 0.198501\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.404000, quantization error: 0.198205\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.413000, quantization error: 0.197903\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.390000, quantization error: 0.197590\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.498000, quantization error: 0.197254\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.407000, quantization error: 0.196904\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.387000, quantization error: 0.196590\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.196268\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.400000, quantization error: 0.195983\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.391000, quantization error: 0.195652\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.485000, quantization error: 0.195307\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.407000, quantization error: 0.194984\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.502000, quantization error: 0.194672\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.494000, quantization error: 0.194395\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.485000, quantization error: 0.194075\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.495000, quantization error: 0.193748\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.482000, quantization error: 0.193403\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.382000, quantization error: 0.193075\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.408000, quantization error: 0.192777\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.596000, quantization error: 0.192464\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.413000, quantization error: 0.192143\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.613000, quantization error: 0.191806\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.618000, quantization error: 0.191457\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.702000, quantization error: 0.191120\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.518000, quantization error: 0.190763\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.605000, quantization error: 0.190415\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.507000, quantization error: 0.190060\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.632000, quantization error: 0.189690\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.513000, quantization error: 0.189320\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.622000, quantization error: 0.188948\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.515000, quantization error: 0.188610\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.501000, quantization error: 0.188268\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.515000, quantization error: 0.187927\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.530000, quantization error: 0.187618\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.417000, quantization error: 0.187295\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.414000, quantization error: 0.187009\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.488000, quantization error: 0.186690\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.616000, quantization error: 0.186356\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.531000, quantization error: 0.186020\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.520000, quantization error: 0.185715\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.524000, quantization error: 0.185394\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.515000, quantization error: 0.185106\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.520000, quantization error: 0.184818\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.502000, quantization error: 0.184518\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.610000, quantization error: 0.184222\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.508000, quantization error: 0.183900\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.611000, quantization error: 0.183595\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.714000, quantization error: 0.183286\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.499000, quantization error: 0.182976\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.498000, quantization error: 0.182691\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.500000, quantization error: 0.182382\n",
      "\n",
      " Final quantization error: 0.182382\n",
      " train took: 58.724000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.085000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.516000, quantization error: 0.951444\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.537000, quantization error: 0.770463\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.548000, quantization error: 0.685501\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.515000, quantization error: 0.655616\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.406000, quantization error: 0.636510\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.508000, quantization error: 0.620320\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.515000, quantization error: 0.604510\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.604000, quantization error: 0.589763\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.704000, quantization error: 0.576687\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.605000, quantization error: 0.564708\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.602000, quantization error: 0.553203\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.606000, quantization error: 0.542238\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.489000, quantization error: 0.531924\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.585000, quantization error: 0.521705\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.499000, quantization error: 0.511892\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.534000, quantization error: 0.502135\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.410000, quantization error: 0.492397\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.507000, quantization error: 0.482405\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.522000, quantization error: 0.472413\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.519000, quantization error: 0.462525\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.490000, quantization error: 0.452509\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.503000, quantization error: 0.442362\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.413000, quantization error: 0.432167\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.416000, quantization error: 0.421903\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.422000, quantization error: 0.411523\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.413000, quantization error: 0.401083\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.413000, quantization error: 0.390803\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.411000, quantization error: 0.380302\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.411000, quantization error: 0.369818\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.412000, quantization error: 0.359068\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.396000, quantization error: 0.348390\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.605000, quantization error: 0.337895\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.499000, quantization error: 0.327385\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.412000, quantization error: 0.316766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 35 ---> elapsed time:  0.494000, quantization error: 0.305913\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.409000, quantization error: 0.295133\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.412000, quantization error: 0.284436\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.425000, quantization error: 0.273973\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.392000, quantization error: 0.263468\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.409000, quantization error: 0.253015\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.400000, quantization error: 0.242719\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.397000, quantization error: 0.241221\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.395000, quantization error: 0.239982\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.394000, quantization error: 0.238999\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.397000, quantization error: 0.238154\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.412000, quantization error: 0.237441\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.416000, quantization error: 0.236818\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.402000, quantization error: 0.236211\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.394000, quantization error: 0.235732\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.385000, quantization error: 0.235309\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.415000, quantization error: 0.234886\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.413000, quantization error: 0.234502\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.390000, quantization error: 0.234131\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.406000, quantization error: 0.233710\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.394000, quantization error: 0.233284\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.399000, quantization error: 0.232894\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.393000, quantization error: 0.232509\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.398000, quantization error: 0.232159\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.386000, quantization error: 0.231816\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.420000, quantization error: 0.231489\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.402000, quantization error: 0.231133\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.508000, quantization error: 0.230755\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.480000, quantization error: 0.230399\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.488000, quantization error: 0.230021\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.497000, quantization error: 0.229651\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.506000, quantization error: 0.229288\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.499000, quantization error: 0.228891\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.391000, quantization error: 0.228532\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.384000, quantization error: 0.228174\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.411000, quantization error: 0.227820\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.394000, quantization error: 0.227422\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.382000, quantization error: 0.227050\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.390000, quantization error: 0.226682\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.401000, quantization error: 0.226350\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.404000, quantization error: 0.225999\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.225604\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.393000, quantization error: 0.225225\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.402000, quantization error: 0.224825\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.402000, quantization error: 0.224432\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.400000, quantization error: 0.224055\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.392000, quantization error: 0.223677\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.504000, quantization error: 0.223304\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.411000, quantization error: 0.222918\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.408000, quantization error: 0.222556\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.410000, quantization error: 0.222187\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.397000, quantization error: 0.221800\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.394000, quantization error: 0.221376\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.401000, quantization error: 0.220988\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.393000, quantization error: 0.220603\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.388000, quantization error: 0.220243\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.379000, quantization error: 0.219883\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.491000, quantization error: 0.219544\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.490000, quantization error: 0.219189\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.404000, quantization error: 0.218833\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.406000, quantization error: 0.218498\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.513000, quantization error: 0.218152\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.494000, quantization error: 0.217787\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.398000, quantization error: 0.217412\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.498000, quantization error: 0.217062\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.485000, quantization error: 0.216713\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.500000, quantization error: 0.216387\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.404000, quantization error: 0.216063\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.508000, quantization error: 0.215705\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.593000, quantization error: 0.215360\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.506000, quantization error: 0.214971\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.507000, quantization error: 0.214613\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.596000, quantization error: 0.214227\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.484000, quantization error: 0.213842\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.426000, quantization error: 0.213457\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.408000, quantization error: 0.213104\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.489000, quantization error: 0.212752\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.400000, quantization error: 0.212370\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.396000, quantization error: 0.211975\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.395000, quantization error: 0.211600\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.387000, quantization error: 0.211226\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.407000, quantization error: 0.210877\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.404000, quantization error: 0.210518\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.398000, quantization error: 0.210151\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.388000, quantization error: 0.209766\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.403000, quantization error: 0.209380\n",
      "\n",
      " Final quantization error: 0.209380\n",
      " train took: 55.072000 seconds\n",
      " Training...\n",
      " pca_linear_initialization took: 0.059000 seconds\n",
      " Rough training...\n",
      " radius_ini: 5.000000 , radius_final: 1.250000, trainlen: 40\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.423000, quantization error: 0.939263\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.411000, quantization error: 0.767783\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.520000, quantization error: 0.679927\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.388000, quantization error: 0.644888\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.389000, quantization error: 0.620396\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.516000, quantization error: 0.601972\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.526000, quantization error: 0.587183\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.402000, quantization error: 0.575297\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.399000, quantization error: 0.564613\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.410000, quantization error: 0.554261\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.400000, quantization error: 0.544038\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.397000, quantization error: 0.533624\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.398000, quantization error: 0.523160\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.396000, quantization error: 0.512945\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.399000, quantization error: 0.502795\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.411000, quantization error: 0.492688\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.399000, quantization error: 0.482481\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.404000, quantization error: 0.472349\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.489000, quantization error: 0.461970\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.491000, quantization error: 0.451629\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.490000, quantization error: 0.441228\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.404000, quantization error: 0.430833\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.612000, quantization error: 0.420383\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.422000, quantization error: 0.409770\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.530000, quantization error: 0.398890\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.408000, quantization error: 0.387830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch: 27 ---> elapsed time:  0.411000, quantization error: 0.376708\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.411000, quantization error: 0.365355\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.412000, quantization error: 0.354068\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.396000, quantization error: 0.342706\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.404000, quantization error: 0.331524\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.513000, quantization error: 0.319967\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.500000, quantization error: 0.308563\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.498000, quantization error: 0.297260\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.626000, quantization error: 0.286212\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.410000, quantization error: 0.275296\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.406000, quantization error: 0.264528\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.520000, quantization error: 0.254049\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.600000, quantization error: 0.243599\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.509000, quantization error: 0.233142\n",
      "\n",
      " Finetune training...\n",
      " radius_ini: 1.250000 , radius_final: 1.000000, trainlen: 80\n",
      "\n",
      " epoch: 1 ---> elapsed time:  0.495000, quantization error: 0.222900\n",
      "\n",
      " epoch: 2 ---> elapsed time:  0.594000, quantization error: 0.221088\n",
      "\n",
      " epoch: 3 ---> elapsed time:  0.475000, quantization error: 0.219826\n",
      "\n",
      " epoch: 4 ---> elapsed time:  0.491000, quantization error: 0.219014\n",
      "\n",
      " epoch: 5 ---> elapsed time:  0.480000, quantization error: 0.218332\n",
      "\n",
      " epoch: 6 ---> elapsed time:  0.392000, quantization error: 0.217660\n",
      "\n",
      " epoch: 7 ---> elapsed time:  0.397000, quantization error: 0.217089\n",
      "\n",
      " epoch: 8 ---> elapsed time:  0.415000, quantization error: 0.216583\n",
      "\n",
      " epoch: 9 ---> elapsed time:  0.398000, quantization error: 0.216076\n",
      "\n",
      " epoch: 10 ---> elapsed time:  0.600000, quantization error: 0.215559\n",
      "\n",
      " epoch: 11 ---> elapsed time:  0.529000, quantization error: 0.215042\n",
      "\n",
      " epoch: 12 ---> elapsed time:  0.530000, quantization error: 0.214528\n",
      "\n",
      " epoch: 13 ---> elapsed time:  0.420000, quantization error: 0.214044\n",
      "\n",
      " epoch: 14 ---> elapsed time:  0.593000, quantization error: 0.213581\n",
      "\n",
      " epoch: 15 ---> elapsed time:  0.387000, quantization error: 0.213152\n",
      "\n",
      " epoch: 16 ---> elapsed time:  0.386000, quantization error: 0.212691\n",
      "\n",
      " epoch: 17 ---> elapsed time:  0.505000, quantization error: 0.212278\n",
      "\n",
      " epoch: 18 ---> elapsed time:  0.491000, quantization error: 0.211847\n",
      "\n",
      " epoch: 19 ---> elapsed time:  0.414000, quantization error: 0.211461\n",
      "\n",
      " epoch: 20 ---> elapsed time:  0.510000, quantization error: 0.211092\n",
      "\n",
      " epoch: 21 ---> elapsed time:  0.409000, quantization error: 0.210742\n",
      "\n",
      " epoch: 22 ---> elapsed time:  0.399000, quantization error: 0.210380\n",
      "\n",
      " epoch: 23 ---> elapsed time:  0.394000, quantization error: 0.210035\n",
      "\n",
      " epoch: 24 ---> elapsed time:  0.403000, quantization error: 0.209685\n",
      "\n",
      " epoch: 25 ---> elapsed time:  0.414000, quantization error: 0.209353\n",
      "\n",
      " epoch: 26 ---> elapsed time:  0.396000, quantization error: 0.209019\n",
      "\n",
      " epoch: 27 ---> elapsed time:  0.396000, quantization error: 0.208687\n",
      "\n",
      " epoch: 28 ---> elapsed time:  0.413000, quantization error: 0.208358\n",
      "\n",
      " epoch: 29 ---> elapsed time:  0.499000, quantization error: 0.208040\n",
      "\n",
      " epoch: 30 ---> elapsed time:  0.395000, quantization error: 0.207715\n",
      "\n",
      " epoch: 31 ---> elapsed time:  0.397000, quantization error: 0.207390\n",
      "\n",
      " epoch: 32 ---> elapsed time:  0.498000, quantization error: 0.207052\n",
      "\n",
      " epoch: 33 ---> elapsed time:  0.400000, quantization error: 0.206704\n",
      "\n",
      " epoch: 34 ---> elapsed time:  0.403000, quantization error: 0.206359\n",
      "\n",
      " epoch: 35 ---> elapsed time:  0.396000, quantization error: 0.206040\n",
      "\n",
      " epoch: 36 ---> elapsed time:  0.397000, quantization error: 0.205736\n",
      "\n",
      " epoch: 37 ---> elapsed time:  0.412000, quantization error: 0.205426\n",
      "\n",
      " epoch: 38 ---> elapsed time:  0.395000, quantization error: 0.205108\n",
      "\n",
      " epoch: 39 ---> elapsed time:  0.397000, quantization error: 0.204762\n",
      "\n",
      " epoch: 40 ---> elapsed time:  0.397000, quantization error: 0.204412\n",
      "\n",
      " epoch: 41 ---> elapsed time:  0.404000, quantization error: 0.204055\n",
      "\n",
      " epoch: 42 ---> elapsed time:  0.392000, quantization error: 0.203697\n",
      "\n",
      " epoch: 43 ---> elapsed time:  0.393000, quantization error: 0.203361\n",
      "\n",
      " epoch: 44 ---> elapsed time:  0.399000, quantization error: 0.203034\n",
      "\n",
      " epoch: 45 ---> elapsed time:  0.397000, quantization error: 0.202682\n",
      "\n",
      " epoch: 46 ---> elapsed time:  0.412000, quantization error: 0.202333\n",
      "\n",
      " epoch: 47 ---> elapsed time:  0.412000, quantization error: 0.201955\n",
      "\n",
      " epoch: 48 ---> elapsed time:  0.411000, quantization error: 0.201617\n",
      "\n",
      " epoch: 49 ---> elapsed time:  0.397000, quantization error: 0.201305\n",
      "\n",
      " epoch: 50 ---> elapsed time:  0.415000, quantization error: 0.200962\n",
      "\n",
      " epoch: 51 ---> elapsed time:  0.398000, quantization error: 0.200630\n",
      "\n",
      " epoch: 52 ---> elapsed time:  0.428000, quantization error: 0.200274\n",
      "\n",
      " epoch: 53 ---> elapsed time:  0.388000, quantization error: 0.199901\n",
      "\n",
      " epoch: 54 ---> elapsed time:  0.406000, quantization error: 0.199551\n",
      "\n",
      " epoch: 55 ---> elapsed time:  0.393000, quantization error: 0.199194\n",
      "\n",
      " epoch: 56 ---> elapsed time:  0.414000, quantization error: 0.198834\n",
      "\n",
      " epoch: 57 ---> elapsed time:  0.396000, quantization error: 0.198498\n",
      "\n",
      " epoch: 58 ---> elapsed time:  0.413000, quantization error: 0.198161\n",
      "\n",
      " epoch: 59 ---> elapsed time:  0.400000, quantization error: 0.197804\n",
      "\n",
      " epoch: 60 ---> elapsed time:  0.395000, quantization error: 0.197447\n",
      "\n",
      " epoch: 61 ---> elapsed time:  0.395000, quantization error: 0.197110\n",
      "\n",
      " epoch: 62 ---> elapsed time:  0.398000, quantization error: 0.196783\n",
      "\n",
      " epoch: 63 ---> elapsed time:  0.396000, quantization error: 0.196445\n",
      "\n",
      " epoch: 64 ---> elapsed time:  0.397000, quantization error: 0.196093\n",
      "\n",
      " epoch: 65 ---> elapsed time:  0.398000, quantization error: 0.195754\n",
      "\n",
      " epoch: 66 ---> elapsed time:  0.402000, quantization error: 0.195427\n",
      "\n",
      " epoch: 67 ---> elapsed time:  0.397000, quantization error: 0.195053\n",
      "\n",
      " epoch: 68 ---> elapsed time:  0.399000, quantization error: 0.194694\n",
      "\n",
      " epoch: 69 ---> elapsed time:  0.398000, quantization error: 0.194343\n",
      "\n",
      " epoch: 70 ---> elapsed time:  0.398000, quantization error: 0.193974\n",
      "\n",
      " epoch: 71 ---> elapsed time:  0.401000, quantization error: 0.193630\n",
      "\n",
      " epoch: 72 ---> elapsed time:  0.407000, quantization error: 0.193292\n",
      "\n",
      " epoch: 73 ---> elapsed time:  0.398000, quantization error: 0.192947\n",
      "\n",
      " epoch: 74 ---> elapsed time:  0.397000, quantization error: 0.192632\n",
      "\n",
      " epoch: 75 ---> elapsed time:  0.398000, quantization error: 0.192328\n",
      "\n",
      " epoch: 76 ---> elapsed time:  0.397000, quantization error: 0.192004\n",
      "\n",
      " epoch: 77 ---> elapsed time:  0.398000, quantization error: 0.191659\n",
      "\n",
      " epoch: 78 ---> elapsed time:  0.397000, quantization error: 0.191337\n",
      "\n",
      " epoch: 79 ---> elapsed time:  0.397000, quantization error: 0.191011\n",
      "\n",
      " epoch: 80 ---> elapsed time:  0.399000, quantization error: 0.190673\n",
      "\n",
      " Final quantization error: 0.190673\n",
      " train took: 53.420000 seconds\n"
     ]
    }
   ],
   "source": [
    "# based on prior optimization\n",
    "map_best = [29, 35] \n",
    "initialization = 'pca'\n",
    "names = ['SSS','SST','MLD','pCO2']\n",
    "tr = 40\n",
    "tf = 80\n",
    "\n",
    "for i in range(12):\n",
    "    ss = StandardScaler().fit_transform(Monthly['month-'+str(i+1)][['SSS','SST','MLD','pCO2']])\n",
    "    \n",
    "    \n",
    "    sm = sompy.SOMFactory().build(ss, mapsize = map_best, mapshape = 'planar',\n",
    "                            initialization='pca',\n",
    "                            normalization = 'var', \n",
    "                            component_names=names, lattice='rect') \n",
    "    sm.train(n_job=4, \n",
    "             verbose='info', \n",
    "             train_rough_len=tr,\n",
    "             train_finetune_len=tf,\n",
    "             #train_rough_radiusin=14,\n",
    "             #train_rough_radiusfin=3.5,\n",
    "             #train_finetune_radiusin=3.5,\n",
    "             #train_finetune_radiusfin=1\n",
    "            ) \n",
    "    \n",
    "    joblib.dump(sm, \"optimized_month_{}.joblib\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study the models trained and plot the errors obtained in order to select the best one\n",
    "models_pool_opt_m = glob.glob(\"./optimized_month*\")\n",
    "errors=[]\n",
    "for model_filepath in models_pool_opt_m:\n",
    "    sm_opt_m = joblib.load(model_filepath)\n",
    "    topographic_error = sm_opt_m.calculate_topographic_error()\n",
    "    quantization_error = sm_opt_m.calculate_quantization_error()\n",
    "    errors.append((topographic_error, quantization_error))\n",
    "e_top_opt_m, e_q_opt_m = zip(*errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(e_top_opt_m, e_q_opt_m)\n",
    "plt.title(\"Optimized Hyperparameters - Month-based Model Perf\")\n",
    "plt.xlabel(\"Topographic error\")\n",
    "plt.ylabel(\"Quantization error\")\n",
    "plt.savefig('Optimized_Model_Monthly_Top_Quant_Errors.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization_error</th>\n",
       "      <th>topographical_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.\\optimized_month_5.joblib</td>\n",
       "      <td>0.091407</td>\n",
       "      <td>0.133423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.\\optimized_month_8.joblib</td>\n",
       "      <td>0.061564</td>\n",
       "      <td>0.143658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\optimized_month_11.joblib</td>\n",
       "      <td>0.086847</td>\n",
       "      <td>0.147459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.\\optimized_month_4.joblib</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>0.149482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.\\optimized_month_7.joblib</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>0.155843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\optimized_month_12.joblib</td>\n",
       "      <td>0.079049</td>\n",
       "      <td>0.158694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.\\optimized_month_3.joblib</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.158889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.\\optimized_month_9.joblib</td>\n",
       "      <td>0.064769</td>\n",
       "      <td>0.162032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\optimized_month_1.joblib</td>\n",
       "      <td>0.070629</td>\n",
       "      <td>0.163909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\optimized_month_2.joblib</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.164323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\optimized_month_10.joblib</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.\\optimized_month_6.joblib</td>\n",
       "      <td>0.077074</td>\n",
       "      <td>0.175631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  quantization_error  topographical_error\n",
       "7    .\\optimized_month_5.joblib            0.091407             0.133423\n",
       "10   .\\optimized_month_8.joblib            0.061564             0.143658\n",
       "2   .\\optimized_month_11.joblib            0.086847             0.147459\n",
       "6    .\\optimized_month_4.joblib            0.075683             0.149482\n",
       "9    .\\optimized_month_7.joblib            0.062668             0.155843\n",
       "3   .\\optimized_month_12.joblib            0.079049             0.158694\n",
       "5    .\\optimized_month_3.joblib            0.069300             0.158889\n",
       "11   .\\optimized_month_9.joblib            0.064769             0.162032\n",
       "0    .\\optimized_month_1.joblib            0.070629             0.163909\n",
       "4    .\\optimized_month_2.joblib            0.070287             0.164323\n",
       "1   .\\optimized_month_10.joblib            0.076054             0.166200\n",
       "8    .\\optimized_month_6.joblib            0.077074             0.175631"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_model_perf = []\n",
    "for i, model_filepath in enumerate(models_pool_opt_m):\n",
    "    monthly_model_perf.append({'model': model_filepath, 'topographical_error': e_top_opt_m[i], 'quantization_error': e_q_opt_m[i]})\n",
    "    #print(model_filepath)\n",
    "    #name.append(model_filepath[3:10])\n",
    "    #err_top.append(e_top[i])\n",
    "    #err_quant.append(e_q[i])\n",
    "\n",
    "month_perf = pd.DataFrame(monthly_model_perf)\n",
    "month_perf.sort_values(['topographical_error'], ascending=True)\n",
    "#print(model_filepath,e_top[i],e_q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    som = joblib.load('C:\\\\Users\\goyetc\\\\SOMPY\\\\optimized_month_{}.joblib'.format(i+1))\n",
    "    map_labels_k5 = som.cluster(n_clusters=5)\n",
    "    data_labels_k5 = np.array([map_labels_k5[int(k)] for k in som._bmu[0]])\n",
    "    map_labels_k10 = som.cluster(n_clusters=10)\n",
    "    data_labels_k10 = np.array([map_labels_k10[int(k)] for k in som._bmu[0]])\n",
    "    map_labels_k15 = som.cluster(n_clusters=15)\n",
    "    data_labels_k15 = np.array([map_labels_k15[int(k)] for k in som._bmu[0]])\n",
    "    \n",
    "    Monthly['month-{}'.format(i+1)]['k=5'] = data_labels_k5\n",
    "    Monthly['month-{}'.format(i+1)]['k=10'] = data_labels_k10\n",
    "    Monthly['month-{}'.format(i+1)]['k=15'] = data_labels_k15\n",
    "    \n",
    "    Monthly['month-{}'.format(i+1)].to_csv('C:\\\\Users\\\\goyetc\\\\ocean-co2-absorption\\\\notebooks\\\\SOM\\\\SOM_Month_{}.csv'.format(i+1),\n",
    "                  sep=',',\n",
    "                  na_rep='NaN',\n",
    "                  columns=[u'ylat', u'xlon', u'SSS', u'MLD', u'SST', u'pCO2', u'k=5', u'k=10', u'k=15'],\n",
    "                  header=True,\n",
    "                  index=True,\n",
    "                  mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ylat</th>\n",
       "      <th>xlon</th>\n",
       "      <th>SSS</th>\n",
       "      <th>MLD</th>\n",
       "      <th>SST</th>\n",
       "      <th>pCO2</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=10</th>\n",
       "      <th>k=15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18671</th>\n",
       "      <td>-13.5</td>\n",
       "      <td>346.5</td>\n",
       "      <td>36.294323</td>\n",
       "      <td>38.994919</td>\n",
       "      <td>25.494459</td>\n",
       "      <td>373.012956</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39912</th>\n",
       "      <td>86.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>33.161171</td>\n",
       "      <td>79.945076</td>\n",
       "      <td>-1.801534</td>\n",
       "      <td>344.781629</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>-30.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>34.762211</td>\n",
       "      <td>28.291983</td>\n",
       "      <td>20.710423</td>\n",
       "      <td>357.380964</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>-51.5</td>\n",
       "      <td>324.5</td>\n",
       "      <td>33.574509</td>\n",
       "      <td>37.789185</td>\n",
       "      <td>7.450382</td>\n",
       "      <td>247.412134</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17261</th>\n",
       "      <td>-18.5</td>\n",
       "      <td>255.5</td>\n",
       "      <td>36.219727</td>\n",
       "      <td>52.492203</td>\n",
       "      <td>24.801188</td>\n",
       "      <td>389.998410</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29016</th>\n",
       "      <td>27.5</td>\n",
       "      <td>143.5</td>\n",
       "      <td>34.494514</td>\n",
       "      <td>107.625160</td>\n",
       "      <td>19.369177</td>\n",
       "      <td>304.221090</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>-50.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>33.762821</td>\n",
       "      <td>53.730377</td>\n",
       "      <td>8.088168</td>\n",
       "      <td>304.816390</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20935</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>33.607609</td>\n",
       "      <td>50.950848</td>\n",
       "      <td>28.088097</td>\n",
       "      <td>360.537081</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10829</th>\n",
       "      <td>-40.5</td>\n",
       "      <td>238.5</td>\n",
       "      <td>34.139713</td>\n",
       "      <td>31.738649</td>\n",
       "      <td>17.431696</td>\n",
       "      <td>395.392641</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25016</th>\n",
       "      <td>10.5</td>\n",
       "      <td>176.5</td>\n",
       "      <td>34.009727</td>\n",
       "      <td>81.422745</td>\n",
       "      <td>26.756647</td>\n",
       "      <td>334.023750</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ylat   xlon        SSS         MLD        SST        pCO2  k=5  k=10  \\\n",
       "18671 -13.5  346.5  36.294323   38.994919  25.494459  373.012956    2     0   \n",
       "39912  86.5  317.5  33.161171   79.945076  -1.801534  344.781629    0     1   \n",
       "13807 -30.5   14.5  34.762211   28.291983  20.710423  357.380964    2     0   \n",
       "7086  -51.5  324.5  33.574509   37.789185   7.450382  247.412134    4     7   \n",
       "17261 -18.5  255.5  36.219727   52.492203  24.801188  389.998410    2     0   \n",
       "29016  27.5  143.5  34.494514  107.625160  19.369177  304.221090    2     2   \n",
       "7218  -50.5   96.5  33.762821   53.730377   8.088168  304.816390    4     7   \n",
       "20935  -4.5   78.5  33.607609   50.950848  28.088097  360.537081    2     8   \n",
       "10829 -40.5  238.5  34.139713   31.738649  17.431696  395.392641    2     0   \n",
       "25016  10.5  176.5  34.009727   81.422745  26.756647  334.023750    2     8   \n",
       "\n",
       "       k=15  \n",
       "18671     7  \n",
       "39912    13  \n",
       "13807     7  \n",
       "7086      3  \n",
       "17261     7  \n",
       "29016     0  \n",
       "7218      3  \n",
       "20935    11  \n",
       "10829     5  \n",
       "25016    11  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Monthly['month-2'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
